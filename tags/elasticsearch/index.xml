<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>ElasticSearch on lexqinMike</title>
        <link>https://mikeLing-qx.github.io/tags/elasticsearch/</link>
        <description>Recent content in ElasticSearch on lexqinMike</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>LexqinMike</copyright>
        <lastBuildDate>Fri, 03 Jan 2025 14:19:32 +0800</lastBuildDate><atom:link href="https://mikeLing-qx.github.io/tags/elasticsearch/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>ElasticSearch进阶与开发实录</title>
        <link>https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/</link>
        <pubDate>Fri, 03 Jan 2025 14:19:32 +0800</pubDate>
        
        <guid>https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/</guid>
        <description>&lt;h1 id=&#34;0-mapping&#34;&gt;0. mapping
&lt;/h1&gt;&lt;h2 id=&#34;1-概述&#34;&gt;1. 概述
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/images/image-20221013153414506.png&#34;
	width=&#34;580&#34;
	height=&#34;339&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20221013153414506&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;171&#34;
		data-flex-basis=&#34;410px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;2-数据类型&#34;&gt;2. 数据类型
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/images/image-20221013153511735.png&#34;
	width=&#34;459&#34;
	height=&#34;314&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20221013153511735&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;146&#34;
		data-flex-basis=&#34;350px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;3-dynamic-mapping&#34;&gt;3. dynamic Mapping
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/images/image-20221013153938176.png&#34;
	width=&#34;695&#34;
	height=&#34;335&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20221013153938176&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;207&#34;
		data-flex-basis=&#34;497px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;类型自动识别的方式&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/images/image-20221013154041195.png&#34;
	width=&#34;634&#34;
	height=&#34;342&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20221013154041195&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;185&#34;
		data-flex-basis=&#34;444px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;4-mapping-的更改&#34;&gt;4. mapping 的更改
&lt;/h2&gt;&lt;p&gt;只能新增, 不能修改&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/images/image-20221013160351812.png&#34;
	width=&#34;641&#34;
	height=&#34;419&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20221013160351812&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;152&#34;
		data-flex-basis=&#34;367px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;5-配置&#34;&gt;5. 配置
&lt;/h2&gt;&lt;h3 id=&#34;1-默认配置&#34;&gt;1. 默认配置
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/images/image-20221013161750154.png&#34;
	width=&#34;572&#34;
	height=&#34;250&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20221013161750154&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;228&#34;
		data-flex-basis=&#34;549px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;2-null_value&#34;&gt;2. null_value
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;需要对null 值实现搜索&lt;/li&gt;
&lt;li&gt;只有 keyword 类型支持设定 null_value&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3-数组类型&#34;&gt;3. 数组类型
&lt;/h3&gt;&lt;p&gt;ElasticSearch 不提供专门的数组类型, 但是任何字段, 都可以包含多个相同类类型的数值&lt;/p&gt;
&lt;h3 id=&#34;4-copy-to&#34;&gt;4. copy to
&lt;/h3&gt;&lt;p&gt;在mapping 上进行配置, 搜索的时候 可以把两个字段的进行一个联合的搜索&lt;/p&gt;
&lt;h2 id=&#34;6-多字段特性&#34;&gt;6. 多字段特性
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/images/image-20221013170626069.png&#34;
	width=&#34;721&#34;
	height=&#34;328&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20221013170626069&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;219&#34;
		data-flex-basis=&#34;527px&#34;
	
&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;It is often useful to index the same field in different ways for different purposes. This is the purpose of multi-fields. For instance, a string field could be mapped as a text field for full-text search, and as a keyword field for sorting or aggregations:
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;7-自定义分词&#34;&gt;7. 自定义分词
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;character filter&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在Tokenizer 之前对文本进行处理, 例如 增删替换字符串, 会影响tokenizer 的 position 和offset 信息&lt;/p&gt;
&lt;p&gt;自带的&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Html strip &amp;ndash; 去除html 标签&lt;/li&gt;
&lt;li&gt;Mapping &amp;ndash; 字符串替换&lt;/li&gt;
&lt;li&gt;Pattern -filter &amp;ndash; 正则匹配替换&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;tokenizer&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;将原始的文本按照一定的规则, 切分为词 (term or token)&lt;/p&gt;
&lt;p&gt;有内置的, 也可以用 Java 开发插件, 实现自己的 Tokenizer&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;token filter&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;将Tokenizer 输出的单词, 进行增加, 修改, 删除&lt;/p&gt;
&lt;p&gt;自带的: lowercase /stop /synonym (添加近义词)&lt;/p&gt;
&lt;h1 id=&#34;1-版本对照&#34;&gt;1. 版本对照
&lt;/h1&gt;&lt;p&gt;spring boot data elasticsearch 版本: 7.6.2&lt;/p&gt;
&lt;p&gt;项目spring boot version: 2.5.4&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; | Spring Data Release Train                                    | Spring Data Elasticsearch                                    | Elasticsearch | Spring Framework | Spring Boot |
| &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash; | &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash; | &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;- | &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;- | &amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash; |
| 2022.0 (Turing)                                              | 5.0.x                                                        | 8.4.2         | 6.0.x            | 3.0.x?      |
| 2021.2 (Raj)                                                 | 4.4.x                                                        | 7.17.3        | 5.3.x            | 2.7.x       |
| 2021.1 (Q)                                                   | 4.3.x                                                        | 7.15.2        | 5.3.x            | 2.6.x       |
| 2021.0 (Pascal)                                              | 4.2.x[&lt;a class=&#34;link&#34; href=&#34;https://github.com/spring-projects/spring-data-elasticsearch/blob/main/src/main/asciidoc/preface.adoc#_footnotedef_1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1&lt;/a&gt;] | 7.12.0        | 5.3.x            | 2.5.x       |
| 2020.0 (Ockham)[&lt;a class=&#34;link&#34; href=&#34;https://github.com/spring-projects/spring-data-elasticsearch/blob/main/src/main/asciidoc/preface.adoc#_footnotedef_1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1&lt;/a&gt;] | 4.1.x[&lt;a class=&#34;link&#34; href=&#34;https://github.com/spring-projects/spring-data-elasticsearch/blob/main/src/main/asciidoc/preface.adoc#_footnotedef_1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1&lt;/a&gt;] | 7.9.3         | 5.3.2            | 2.4.x       |
| Neumann[&lt;a class=&#34;link&#34; href=&#34;https://github.com/spring-projects/spring-data-elasticsearch/blob/main/src/main/asciidoc/preface.adoc#_footnotedef_1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1&lt;/a&gt;] | 4.0.x[&lt;a class=&#34;link&#34; href=&#34;https://github.com/spring-projects/spring-data-elasticsearch/blob/main/src/main/asciidoc/preface.adoc#_footnotedef_1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1&lt;/a&gt;] | 7.6.2         | 5.2.12           | 2.3.x       |
| Moore[&lt;a class=&#34;link&#34; href=&#34;https://github.com/spring-projects/spring-data-elasticsearch/blob/main/src/main/asciidoc/preface.adoc#_footnotedef_1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1&lt;/a&gt;] | 3.2.x[&lt;a class=&#34;link&#34; href=&#34;https://github.com/spring-projects/spring-data-elasticsearch/blob/main/src/main/asciidoc/preface.adoc#_footnotedef_1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1&lt;/a&gt;] | 6.8.12        | 5.2.12           | 2.2.x       |
| Lovelace[&lt;a class=&#34;link&#34; href=&#34;https://github.com/spring-projects/spring-data-elasticsearch/blob/main/src/main/asciidoc/preface.adoc#_footnotedef_1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1&lt;/a&gt;] | 3.1.x[&lt;a class=&#34;link&#34; href=&#34;https://github.com/spring-projects/spring-data-elasticsearch/blob/main/src/main/asciidoc/preface.adoc#_footnotedef_1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1&lt;/a&gt;] | 6.2.2         | 5.1.19           | 2.1.x       |
| Kay[&lt;a class=&#34;link&#34; href=&#34;https://github.com/spring-projects/spring-data-elasticsearch/blob/main/src/main/asciidoc/preface.adoc#_footnotedef_1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1&lt;/a&gt;] | 3.0.x[&lt;a class=&#34;link&#34; href=&#34;https://github.com/spring-projects/spring-data-elasticsearch/blob/main/src/main/asciidoc/preface.adoc#_footnotedef_1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1&lt;/a&gt;] | 5.5.0         | 5.0.13           | 2.0.x       |
| Ingalls[&lt;a class=&#34;link&#34; href=&#34;https://github.com/spring-projects/spring-data-elasticsearch/blob/main/src/main/asciidoc/preface.adoc#_footnotedef_1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1&lt;/a&gt;] | 2.1.x[&lt;a class=&#34;link&#34; href=&#34;https://github.com/spring-projects/spring-data-elasticsearch/blob/main/src/main/asciidoc/preface.adoc#_footnotedef_1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1&lt;/a&gt;] | 2.4.0         | 4.3.25           | 1.5.x       |&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;提供操作es-api 的框架&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;spring-data

sparkStreaming

Flink
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;https://blog.csdn.net/u011863024/article/details/115721328
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;2-常用分词器&#34;&gt;2. 常用分词器
&lt;/h1&gt;&lt;p&gt;自带&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Standard Analyzer&lt;/strong&gt; - 默认分词器，按英文空格切分&lt;/p&gt;
&lt;p&gt;Simple Analyzer - 按照非字母切分(符号被过滤)&lt;/p&gt;
&lt;p&gt;Stop Analyzer - 小写处理，停用词过滤(the,a,is)&lt;/p&gt;
&lt;p&gt;Whitespace Analyzer - 按照空格切分，不转小写&lt;/p&gt;
&lt;p&gt;Keyword Analyzer - 不分词，直接将输入当作输出&lt;/p&gt;
&lt;p&gt;Patter Analyzer - 正则表达式，默认\W+(非字符分割)&lt;/p&gt;
&lt;p&gt;中文&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;&lt;strong&gt;分词器&lt;/strong&gt;&lt;/th&gt;
          &lt;th&gt;&lt;strong&gt;优势&lt;/strong&gt;&lt;/th&gt;
          &lt;th&gt;&lt;strong&gt;劣势&lt;/strong&gt;&lt;/th&gt;
          &lt;th&gt;&lt;strong&gt;地址&lt;/strong&gt;&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;IK Analyzer&lt;/td&gt;
          &lt;td&gt;简单易用，支持自定义词典和远程词典&lt;/td&gt;
          &lt;td&gt;词库需要自行维护，不支持词性识别&lt;/td&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/medcl/elasticsearch-analysis-ik&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/medcl/elasticsearch-analysis-ik&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Ansj&lt;/td&gt;
          &lt;td&gt;分词精准度不错，支持词性识别&lt;/td&gt;
          &lt;td&gt;对标hanlp词库略少，学习成本高&lt;/td&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/NLPchina/elasticsearch-analysis-ansj&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/NLPchina/elasticsearch-analysis-ansj&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;jieba&lt;/td&gt;
          &lt;td&gt;新词发现功能&lt;/td&gt;
          &lt;td&gt;不支持词性识别&lt;/td&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/sing1ee/elasticsearch-jieba-plugin&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/sing1ee/elasticsearch-jieba-plugin&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Smart Chinese Analyzer&lt;/td&gt;
          &lt;td&gt;官方插件&lt;/td&gt;
          &lt;td&gt;中文分词效果惨不忍睹&lt;/td&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://artifacts.elastic.co/downloads/elasticsearch-plugins/analysis-smartcn/analysis-smartcn-7.16.1.zip&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://artifacts.elastic.co/downloads/elasticsearch-plugins/analysis-smartcn/analysis-smartcn-7.16.1.zip&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Hanlp&lt;/td&gt;
          &lt;td&gt;目前词库最完善，支持的特性非常多&lt;/td&gt;
          &lt;td&gt;需要更优的分词效果，学习成本高&lt;/td&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/hankcs/HanLP/releases&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/hankcs/HanLP/releases&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h1 id=&#34;3-ik-分词器远程字典&#34;&gt;3. ik 分词器远程字典
&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;ik 分词器会==每隔 1 分钟调用一次 head 方法根据 etag 来判断字典是否更新了==，如果更新了的话才会调用 get 方法去下载字典。先调用 head 方法确认更新后再调用 get下载，这样就节省了带宽流量，也省的去更新词典了。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;1-配置文件&#34;&gt;1. 配置文件
&lt;/h3&gt;&lt;p&gt;/xxx/elasticsearch-7.12.0/plugins/ik/config/IKAnalyzer.cfg.xml&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt;
&amp;lt;!DOCTYPE properties SYSTEM &amp;quot;http://java.sun.com/dtd/properties.dtd&amp;quot;&amp;gt;
&amp;lt;properties&amp;gt;
	&amp;lt;comment&amp;gt;IK Analyzer 扩展配置&amp;lt;/comment&amp;gt;
	&amp;lt;!--用户可以在这里配置自己的扩展字典 --&amp;gt;
	&amp;lt;entry key=&amp;quot;ext_dict&amp;quot;&amp;gt;shfq_ext_dic.dic&amp;lt;/entry&amp;gt;
	 &amp;lt;!--用户可以在这里配置自己的扩展停止词字典--&amp;gt;
	&amp;lt;entry key=&amp;quot;ext_stopwords&amp;quot;&amp;gt;&amp;lt;/entry&amp;gt;
	&amp;lt;!--用户可以在这里配置远程扩展字典 --&amp;gt;
	&amp;lt;entry key=&amp;quot;remote_ext_dict&amp;quot;&amp;gt;http://localhost:8162/test/downloadExtDic?fileName=extWords.dic&amp;lt;/entry&amp;gt;
	&amp;lt;!--用户可以在这里配置远程扩展停止词字典--&amp;gt;
	&amp;lt;entry key=&amp;quot;remote_ext_stopwords&amp;quot;&amp;gt;http://localhost:8162/test/downloadExtDic?fileName=stopWords.dic&amp;lt;/entry&amp;gt;
&amp;lt;/properties&amp;gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;2-接口实现&#34;&gt;2. 接口实现
&lt;/h3&gt;&lt;p&gt;在下载扩展、停用词典的接口里返回 Last-Modified 或 ETag responder header 。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import com.huitongjy.common.util.LogUtils;
import io.swagger.annotations.Api;
import io.swagger.models.HttpMethod;
import org.apache.commons.lang3.StringUtils;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.core.io.UrlResource;
import org.springframework.http.HttpHeaders;
import org.springframework.http.MediaType;
import org.springframework.http.ResponseEntity;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;
import javax.servlet.http.HttpServletRequest;
import java.io.File;
import java.io.IOException;
import java.net.MalformedURLException;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.nio.file.attribute.BasicFileAttributes;

@RestController
@Api(value = &amp;quot;PrivateController&amp;quot;, tags = &amp;quot;测试&amp;quot;)

public class TestController {
    private static final Logger LOG = LoggerFactory.getLogger(PrivateController.class);

    @RequestMapping(value = &amp;quot;/test/downloadExtDic&amp;quot;)
    public ResponseEntity&amp;lt;org.springframework.core.io.Resource&amp;gt; downloadFileFromLocal(HttpServletRequest request, String fileName) {
        if (StringUtils.isEmpty(fileName)) {
            return null;
        }
        // 可以把字典的配置文件写到配置中心
        String location = &amp;quot;&amp;quot;;
        if (!location.endsWith(File.separator)) {
            location += File.separator;
        }
        String method = request.getMethod();
        boolean isHead = HttpMethod.HEAD.name().equals(method);
        String pathStr = location + fileName;
        File file = new File(pathStr);
        if (!file.exists()) {
            LogUtils.error(LOG, &amp;quot;字典不存在&amp;quot;, &amp;quot;path&amp;quot;, pathStr);
            return null;
        }

        Path path = Paths.get(pathStr);
        org.springframework.core.io.Resource resource = null;

        try {
            resource = new UrlResource(path.toUri());
        } catch (MalformedURLException e) {
            LogUtils.error(LOG, &amp;quot;加载字典异常&amp;quot;, e);
            return null;
        }
        HttpHeaders httpHeaders = new HttpHeaders();
        httpHeaders.add(HttpHeaders.CONTENT_DISPOSITION, &amp;quot;attachment; filename=\&amp;quot;&amp;quot; + fileName + &amp;quot;\&amp;quot;&amp;quot;);
        httpHeaders.add(HttpHeaders.ETAG, generateLastUpdateDate(path) + &amp;quot;&amp;quot;);
        if (isHead) {
            resource = null;
        }
        return ResponseEntity.ok()
                .contentType(MediaType.TEXT_PLAIN)
                .headers(httpHeaders)
                .body(resource);
    }

    private long generateLastUpdateDate(Path path) {
        try {
            BasicFileAttributes attr = Files.readAttributes(path, BasicFileAttributes.class);
            Long l = attr.lastModifiedTime().toMillis();
            return l;
        } catch (IOException e) {
            return -1;
        }

    }

}

&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;4-问题&#34;&gt;4. 问题
&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;默认的分词请求 最大字数为10000字, 如何修改&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;分词相关参数的含义与使用&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/images/image-20220927121228770.png&#34;
	width=&#34;311&#34;
	height=&#34;182&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220927121228770&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;170&#34;
		data-flex-basis=&#34;410px&#34;
	
&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;# 只能为指定的index进行分词
PUT /analyze_sample
{
  &amp;quot;settings&amp;quot; : {
    &amp;quot;index.analyze.max_token_count&amp;quot; : 100000
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;文档先于关键词添加, 倒排索引已经生成过了, 后续添加了关键词 之后进行搜索的时候能否命中?&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;验证流程:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;先添加文章&lt;/li&gt;
&lt;li&gt;分词器&amp;ndash;添加关键词&lt;/li&gt;
&lt;li&gt;搜索&lt;/li&gt;
&lt;li&gt;分析词条索引&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;注意 : ==对新添加的索引数据就会按照扩展词典进行分词。但是原有的索引数据不会，需要对原有数据重新生成索引==&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;能否给ik分词器配置多个远程的拓展词库&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;不行&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;ElasticsearchTemplate 注入失败的原因是什么?&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;springboot集成es的版本更新很快，在7.x版本已经弃用了ElasticSearchTemplate，进而使用ElasticSearchRestTemplate&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;如何进行精确搜索?&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;使用standard 分词, match_pharse 查询&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol start=&#34;7&#34;&gt;
&lt;li&gt;
&lt;p&gt;es 的index 名必须是小写的 !&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;嵌套文档查询&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;nested中查询的是嵌套文档的内容，语法与正常查询时一致。&lt;/p&gt;
&lt;p&gt;文档的分数计算需注意&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;nested 查询肯定可以匹配到多个嵌套的文档。每一个匹配的嵌套文档都有自己的相关度得分，但是这众多的分数最终需要汇聚为可供根文档使用的一个分数&lt;/li&gt;
&lt;li&gt;默认情况下，根文档的分数是这些嵌套文档分数的平均值。可以通过设置 score_mode 参数来控制这个得分策略，相关策略有 avg (平均值), max (最大值), sum (加和) 和 none (直接返回 1.0 常数值分数)。&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;ol start=&#34;9&#34;&gt;
&lt;li&gt;词条出现次数统计&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;​		配置termvectors, 本质还是空间换时间&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;POST message_index/_bulk
{&amp;quot;index&amp;quot;:{&amp;quot;_id&amp;quot;:1}}
{&amp;quot;message&amp;quot;:&amp;quot;沉溺于「轻易获得高成就感」的事情：沉溺于有意无意地寻求用很小付出获得很大「huibao」的偏方，哪怕huibao是虚拟的&amp;quot;}
{&amp;quot;index&amp;quot;:{&amp;quot;_id&amp;quot;:2}}
{&amp;quot;message&amp;quot;:&amp;quot;过度追求“短期huibao”可以先思考这样一个问题：为什么玩王者荣耀沉溺我们总是停不下来huibao&amp;quot;}
{&amp;quot;index&amp;quot;:{&amp;quot;_id&amp;quot;:3}}
{&amp;quot;message&amp;quot;:&amp;quot;过度追求的努力无法带来超额的huibao，就因此放弃了努力。这点在聪明人身上尤其明显。以前念本科的时候身在沉溺&amp;quot;}

PUT message_index
{
  &amp;quot;mappings&amp;quot;: {
    &amp;quot;properties&amp;quot;: {
      &amp;quot;message&amp;quot;: {
        &amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;,
        &amp;quot;term_vector&amp;quot;: &amp;quot;with_positions_offsets_payloads&amp;quot;,
        &amp;quot;store&amp;quot;: true,
        &amp;quot;analyzer&amp;quot;: &amp;quot;ik_max_word&amp;quot;
      }
    }
  }
}

GET message_index/_termvectors/1?fields=message
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;10&#34;&gt;
&lt;li&gt;自动预警&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;生效范围&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;文件类型&lt;/li&gt;
&lt;li&gt;部门&lt;/li&gt;
&lt;li&gt;发布时间&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;关键词&lt;/p&gt;
&lt;p&gt;首先 &amp;ndash; &amp;gt; IK 分词器拓展词 &amp;ndash;&amp;gt; 会使用所有启用的关键词&lt;/p&gt;
&lt;p&gt;方案1:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;查询出文章对应的筛查关键词&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;计算命中的关键词&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;存储到 article_keyword&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;方案2:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;直接存储到ES中&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;根据每个关键词的生效策略, 使用DSL 语句筛查出对应的文章&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;存储到 article_keyword&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如何打印执行的DSL 语句?&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;参考资料
&lt;a class=&#34;link&#34; href=&#34;https://docs.spring.io/spring-data/elasticsearch/docs/current/reference/html/#repositories.definition&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://docs.spring.io/spring-data/elasticsearch/docs/current/reference/html/#repositories.definition&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;简单处理&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Optional.ofNullable(searchQuery.getFilter()).ifPresent(r -&amp;gt; log.info(&amp;quot;DSL-filter:{}&amp;quot;, r.toString()));

Optional.ofNullable(searchQuery.getQuery()).ifPresent(r -&amp;gt; log.info(&amp;quot;DSL-query:{}&amp;quot;, r.toString()));

Optional.ofNullable(searchQuery.getElasticsearchSorts()).ifPresent(r -&amp;gt; log.info(&amp;quot;Sort-query:{}&amp;quot;, r.toString()));
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;12&#34;&gt;
&lt;li&gt;专项筛查&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;GET article/_search
{
  &amp;quot;query&amp;quot;: {
    &amp;quot;bool&amp;quot;: {
      &amp;quot;should&amp;quot;: [
        {
          &amp;quot;match_phrase&amp;quot;: {
            &amp;quot;contentStandardAnalyzer&amp;quot;: &amp;quot;深圳创新&amp;quot;
          }
        },
        {
          &amp;quot;match_phrase&amp;quot;: {
            &amp;quot;title&amp;quot;: &amp;quot;深圳创新&amp;quot;
          }
        }
      ],
      &amp;quot;must&amp;quot;: [
        {
          &amp;quot;range&amp;quot;: {
            &amp;quot;publicationDate&amp;quot;: {
              &amp;quot;gte&amp;quot;: &amp;quot;2022-09-29&amp;quot;,
              &amp;quot;lte&amp;quot;: &amp;quot;2022-09-30&amp;quot;
            }
          }
        },{
          &amp;quot;terms&amp;quot;: {
            &amp;quot;publicationDeptId&amp;quot;: [
              &amp;quot;4&amp;quot;,
              &amp;quot;5&amp;quot;
            ]
          }
        }
      ]
    } 
  }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;13&#34;&gt;
&lt;li&gt;elasticsearch 事务&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;Elasticsearch 支持单个文档级别的原子创建、更新和删除操作，但没有内置对多文档事务的支持。

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以使用乐观锁, 带上version字段, 或者可以通过外置的关系型数据库进行处理&lt;/p&gt;
&lt;ol start=&#34;14&#34;&gt;
&lt;li&gt;什么是elasticSearch 的子字段&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/multi-fields.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.elastic.co/guide/en/elasticsearch/reference/current/multi-fields.html&lt;/a&gt;&lt;/p&gt;
&lt;ol start=&#34;15&#34;&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;5-精确搜索方案&#34;&gt;5. 精确搜索方案
&lt;/h1&gt;&lt;p&gt;问题描述&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/images/image-20220928180343431.png&#34;
	width=&#34;621&#34;
	height=&#34;212&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220928180343431&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;292&#34;
		data-flex-basis=&#34;703px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;1-multi_field&#34;&gt;1. multi_field
&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;默认情况下使用标准分析器分析字段。如果您想检查完全匹配，您可以存储未分析的字段

&amp;quot;dog&amp;quot;:{
            &amp;quot;type&amp;quot;:&amp;quot;multi_field&amp;quot;,
            &amp;quot;fields&amp;quot;:{
                &amp;quot;dog&amp;quot;:{
                    &amp;quot;include_in_all&amp;quot;:false,
                    &amp;quot;type&amp;quot;:&amp;quot;string&amp;quot;,
                    &amp;quot;index&amp;quot;:&amp;quot;not_analyzed&amp;quot;,
                    &amp;quot;store&amp;quot;:&amp;quot;no&amp;quot;
                },
                &amp;quot;_tokenized&amp;quot;:{
                    &amp;quot;include_in_all&amp;quot;:false,
                    &amp;quot;type&amp;quot;:&amp;quot;string&amp;quot;,
                    &amp;quot;index&amp;quot;:&amp;quot;analyzed&amp;quot;,
                    &amp;quot;store&amp;quot;:&amp;quot;no&amp;quot;
                }
            }
        }


&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;然后您可以查询 dog-field 以获得精确匹配，并查询 dog._tokenized 用于分析查询（如全文）&lt;/p&gt;
&lt;h2 id=&#34;2-standard-分词&#34;&gt;2. Standard 分词
&lt;/h2&gt;&lt;p&gt;结合 bool 查询  should + match_pharse&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/images/image-20220928180207678.png&#34;
	width=&#34;462&#34;
	height=&#34;433&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220928180207678&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;106&#34;
		data-flex-basis=&#34;256px&#34;
	
&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;查询  --&amp;gt; 飞科剃须刀
bool: {
	should: {
		&amp;quot;科剃须&amp;quot;
	}
	match_pharse: {
		&amp;quot;科剃须&amp;quot;
	}
}

&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;6-function_score&#34;&gt;6. function_score
&lt;/h1&gt;&lt;blockquote&gt;
&lt;h6 id=&#34;参考资料-httpsjuejincnpost6844904022948724744&#34;&gt;参考资料: &lt;a class=&#34;link&#34; href=&#34;https://juejin.cn/post/6844904022948724744&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://juejin.cn/post/6844904022948724744&lt;/a&gt;
&lt;/h6&gt;&lt;/blockquote&gt;
&lt;p&gt;Elasticsearch进行全文搜索的时候，==默认是使用BM25计算的_score字段进行降序排序的==。当我们需要用==其他字段进行降序或者升序排序的时候，可以使用sort字段==，传入我们想要的排序字段和方式。 当简单的使用几个字段升降序排列组合无法满足我们的需求的时候，我们就需要==自定义排序的特性==，Elasticsearch提供了function_score的DSL来自定义打分，这样就可以根据自定义的_score来进行排序。&lt;/p&gt;
&lt;p&gt;可以再查询结束后对每一个匹配的文档进行重新算分, 根据新生成的分数进行排序&lt;/p&gt;
&lt;p&gt;算法函数&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;weight : 为每一个文档设置一个简单而不被规范化的权重&lt;/li&gt;
&lt;li&gt;field value factor: 使用该数字来修改_score, 例如将 &amp;ldquo;热度&amp;rdquo; 和&amp;quot;点赞数&amp;quot; 作为算分的参考因素&lt;/li&gt;
&lt;li&gt;random score: 为每一个用户使用一个不同的, 随机算分结果&lt;/li&gt;
&lt;li&gt;衰减函数: 以某个字段的值为标准, 距离某个值越近, 得分越高&lt;/li&gt;
&lt;li&gt;script scores: 自定义脚本完全控制&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一致性随机文档&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;GET article/_search
{
  &amp;quot;from&amp;quot;: 0, 
  &amp;quot;size&amp;quot;: 2,
  &amp;quot;query&amp;quot;: {
    &amp;quot;function_score&amp;quot;: {
      &amp;quot;random_score&amp;quot;: {
        &amp;quot;seed&amp;quot;: 314124
      }
    }
  }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;脚本排序&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;&amp;quot;sort&amp;quot;: [
    {
      &amp;quot;publicationDate&amp;quot;: {
        &amp;quot;order&amp;quot;: &amp;quot;asc&amp;quot;
      }
    },
    {
      &amp;quot;_script&amp;quot;: {
        &amp;quot;script&amp;quot;: {
          &amp;quot;source&amp;quot;: &amp;quot;def type = doc[&#39;book_type&#39;].value; def time = doc[&#39;publish_time&#39;].value;if(type==1) return time; else return -time&amp;quot;,
          &amp;quot;lang&amp;quot;: &amp;quot;painless&amp;quot;
        },
        &amp;quot;type&amp;quot;: &amp;quot;number&amp;quot;,
        &amp;quot;order&amp;quot;: &amp;quot;asc&amp;quot;
      }
    }
  ]

&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;7-constant_score--filter&#34;&gt;7. constant_score + filter
&lt;/h1&gt;&lt;p&gt;TF &amp;ndash; 词频 (检索词频率)&lt;/p&gt;
&lt;p&gt;IDF &amp;ndash; 词在文档中出现的概率 (反向文档频率)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;检索词频率
检索词在该字段出现的频率？出现频率越高，相关性也越高。 字段中出现过 5 次要比只出现过 1 次的相关性高。

反向文档频率
每个检索词在索引中出现的频率？频率越高，相关性越低。检索词出现在多数文档中会比出现在少数文档中的权重更低。

字段长度准则
字段的长度是多少？长度越长，相关性越低。 检索词出现在一个短的 title 要比同样的词出现在一个长的 content 字段权重更大。

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以跳过算分步骤提高系统性能&lt;/p&gt;
&lt;h1 id=&#34;8-bool&#34;&gt;8. bool
&lt;/h1&gt;&lt;h2 id=&#34;1-概述-1&#34;&gt;1. 概述
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;子查询可以任意顺序出现&lt;/li&gt;
&lt;li&gt;可以嵌套多个查询&lt;/li&gt;
&lt;li&gt;如果bool查询中, 没有must条件, should 中必须至少满足一条查询才会有返回&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;2-多值精确匹配&#34;&gt;2. 多值精确匹配
&lt;/h2&gt;&lt;p&gt;对多值字段进行精确匹配的话  例如: List&lt;String&gt;&lt;/p&gt;
&lt;p&gt;可以通过增加一个 genre count 字段进行计数&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/images/image-20221012104355848.png&#34;
	width=&#34;587&#34;
	height=&#34;260&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20221012104355848&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;225&#34;
		data-flex-basis=&#34;541px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;2--算分&#34;&gt;2.  算分
&lt;/h2&gt;&lt;p&gt;算分过程&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;查询should 语句中的两个查询&lt;/li&gt;
&lt;li&gt;加和两个查询的评分&lt;/li&gt;
&lt;li&gt;乘以匹配语句的总数&lt;/li&gt;
&lt;li&gt;除以所有语句的总数&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;must&lt;/th&gt;
          &lt;th&gt;必须匹配, 贡献算分&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;should&lt;/td&gt;
          &lt;td&gt;选择性匹配, 贡献算分&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;must_not&lt;/td&gt;
          &lt;td&gt;filter_context  不贡献算分&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;filter&lt;/td&gt;
          &lt;td&gt;filter_context  不贡献算分&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;bool 查询的结构也会对算分产生影响&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;同一级下的竞争字段会具有相同的权重&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;通过嵌套bool查询, 可以改变对算分的影响&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Boosting 是控制相关度的一种手段
&lt;ul&gt;
&lt;li&gt;索引, 字段 或查询子条件&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;参数 boost 的含义&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;bootst &amp;gt; 1, 打分的相关度相对性提高&lt;/li&gt;
&lt;li&gt;0&amp;lt; boost &amp;lt;1 , 打分的权重相对性降低&lt;/li&gt;
&lt;li&gt;boost &amp;lt; 0, 贡献负分&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/images/image-20221012105349279.png&#34;
	width=&#34;441&#34;
	height=&#34;475&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20221012105349279&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;92&#34;
		data-flex-basis=&#34;222px&#34;
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;9-dix-max-query&#34;&gt;9. dix max query
&lt;/h1&gt;&lt;p&gt;单字符串多字段查询&lt;/p&gt;
&lt;p&gt;会将所有查询字段匹配度最高的 字段来算分&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/images/image-20221012110715127.png&#34;
	width=&#34;364&#34;
	height=&#34;173&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20221012110715127&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;210&#34;
		data-flex-basis=&#34;504px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;tie_breaker 介于0-1 之间的浮点数, 0 代表最佳匹配, 1 代表所有语句同等重要&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;获得最佳匹配语句的评分-score&lt;/li&gt;
&lt;li&gt;将其他匹配语句的评分与tie_breaker 相乘&lt;/li&gt;
&lt;li&gt;对以上评分求和并规范化&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;10-multi-match&#34;&gt;10. multi match
&lt;/h1&gt;&lt;p&gt;单字符串多字段查询&lt;/p&gt;
&lt;p&gt;三种type:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CROSS_FIELDS 希望这个词条的分词词汇是分配到不同字段中的, 支持 Operator
MOST_FIELDS  越多字段匹配的文档分越高 ,⽆法使⽤ Operator
BEST_FIELDS  完全匹配的文档占的评分比较高

&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;11-termpharse-suggester&#34;&gt;11. term&amp;amp;pharse suggester
&lt;/h1&gt;&lt;p&gt;suggester 就是一种特殊类型的搜索,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;搜索引擎中类似的功能，在 Elasticsearch 中是通过 Suggester API 实现的&lt;/li&gt;
&lt;li&gt;原理：将输⼊的⽂本分解为 Token，然后在索引的字典⾥查找相似的 Term 并返回&lt;/li&gt;
&lt;li&gt;Elasticsearch 设计了 4 种类别的 Suggesters
&lt;ul&gt;
&lt;li&gt;Term &amp;amp; Phrase Suggester&lt;/li&gt;
&lt;li&gt;Complete &amp;amp; Context Suggester 自动补全和上下文提示, 不是使用倒排索引的, 只能基于前缀&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;12-聚合分析&#34;&gt;12. 聚合分析
&lt;/h1&gt;&lt;h2 id=&#34;1-bucket--metric-aggregation&#34;&gt;1. bucket &amp;amp; metric aggregation
&lt;/h2&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select count(brand) from cars group by brand;

&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;metric 相当于 count , 一些统计方法&lt;/li&gt;
&lt;li&gt;bucket 相当与group by , 一组满足条件的文档&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​	ES对聚合索引的桶数有限制，默认是10000, 可以进行配置&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/images/image-20221013094517157.png&#34;
	width=&#34;682&#34;
	height=&#34;357&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20221013094517157&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;191&#34;
		data-flex-basis=&#34;458px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;1-metric-aggregation&#34;&gt;1. metric aggregation
&lt;/h3&gt;&lt;p&gt;● 单值分析：只输出⼀个分析结果&lt;/p&gt;
&lt;p&gt;○ min, max, avg, sum&lt;/p&gt;
&lt;p&gt;○ Cardinality （类似 distinct Count）&lt;/p&gt;
&lt;p&gt;● 多值分析：输出多个分析结果&lt;/p&gt;
&lt;p&gt;○ stats, extended stats&lt;/p&gt;
&lt;p&gt;○ percentile, percentile rank&lt;/p&gt;
&lt;p&gt;○ top hits （排在前⾯的示例）&lt;/p&gt;
&lt;h3 id=&#34;2-terms-aggregation&#34;&gt;2. terms aggregation
&lt;/h3&gt;&lt;p&gt;==对于Text 类型的数据默认是关闭的, 需要配置mapping 开启, 但是聚合的时候会对text 类型进行分词的==&lt;/p&gt;
&lt;p&gt;terms 不准的问题:&lt;/p&gt;
&lt;p&gt;原因是, 数据分散在多个分片上, Coordinating node 无法获取数据的全貌&lt;/p&gt;
&lt;p&gt;提升shard_size 的参数, 每次从分片上获取额外多的数据, 提升准确率&lt;/p&gt;
&lt;p&gt;● 按照⼀定的规则，将⽂档分配到不同的&lt;/p&gt;
&lt;p&gt;桶中，从⽽达到分类的⽬的。ES 提供的&lt;/p&gt;
&lt;p&gt;⼀些常⻅的 Bucket Aggregation&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;==Terms==&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;==数字类型==&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;​	● Range / Data Range&lt;/p&gt;
&lt;p&gt;​	● Histogram / Date Histogram&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;==⽀持嵌套==：也就在桶⾥再做分桶&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;优化terms 聚合的性能, 把以下配置打开, 每当加入新数据的时候会自动加入cache(预加载)&lt;/p&gt;
&lt;p&gt;场景&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在当聚合查询比较频繁, 而且会有新文档不断写入的情况下可以打开这个配置&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/images/image-20221013100243416.png&#34;
	width=&#34;395&#34;
	height=&#34;168&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20221013100243416&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;235&#34;
		data-flex-basis=&#34;564px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/7.1/tune-for-search-speed.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.elastic.co/guide/en/elasticsearch/reference/7.1/tune-for-search-speed.html&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;3-range--histogram-aggregation&#34;&gt;3. range &amp;amp; histogram aggregation
&lt;/h3&gt;&lt;p&gt;按照数字的范围，进⾏分桶&lt;/p&gt;
&lt;p&gt;● 在 Range Aggregation 中，可以⾃定义 Key&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;​	Demo：&lt;/p&gt;
&lt;p&gt;​	● 按照⼯资的 Range 分桶&lt;/p&gt;
&lt;p&gt;​	● 按照⼯资的间隔（Histogram）分桶&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;4-bucket--metrix-aggregation&#34;&gt;4. bucket + metrix aggregation
&lt;/h3&gt;&lt;p&gt;Bucket 聚合分析允许通过添加**⼦聚合**分析来进⼀步分析，⼦聚合分析可以是&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;bucket&lt;/li&gt;
&lt;li&gt;metric&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Demo&lt;/p&gt;
&lt;p&gt;● 按照⼯作类型进⾏分桶，并统计⼯资信息&lt;/p&gt;
&lt;p&gt;● 先按照⼯作类型分桶，然后按性别分桶，并统计⼯资信&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;2-pipeline-聚合&#34;&gt;2. Pipeline 聚合
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/images/image-20221013103451402.png&#34;
	width=&#34;633&#34;
	height=&#34;327&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20221013103451402&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;193&#34;
		data-flex-basis=&#34;464px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;管道的概念: 支持对聚合分析的结果, 再次进行聚合&lt;/p&gt;
&lt;p&gt;Pipeline 的 分析结果会输出到原结果中, 根据位置的不同, 分为两类&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Sibling - 结果和现有分析结果同级&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Max, min, Avg &amp;amp; Sum bucket&lt;/li&gt;
&lt;li&gt;Stats, Extended status Bucket&lt;/li&gt;
&lt;li&gt;Percentiles Bucket&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Parent - 结果内嵌到现有的聚合分析结果之中&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Derivative （求导）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cumultive Sum （累计求和）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Moving Function (滑动窗⼝)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;3-聚合作用范围&#34;&gt;3. 聚合作用范围
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;ES 聚合分析的默认作⽤范围是 query 的查询结果集&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;同时 ES 还⽀持以下⽅式改变聚合的作⽤范围&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Filter 只对当前的子聚合语句生效&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Post_Filter&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;是对聚合分析后的⽂档进⾏再次过滤&lt;/li&gt;
&lt;li&gt;size 无需设置为0&lt;/li&gt;
&lt;li&gt;使用场景
&lt;ul&gt;
&lt;li&gt;一条语句, 获取聚合信息 + 获取符合条件的文档&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Global, 无视query, 对全部文档进行统计&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;4-聚合分析&#34;&gt;4. 聚合分析
&lt;/h2&gt;&lt;p&gt;在 Terms Aggregation 的返回中有两个特殊的数值&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;doc_count_error_upper_bound ： 被遗漏的term 分桶，包含的⽂档，有可能的最⼤值&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;sum_other_doc_count: 除了返回结果 bucket 的 terms 以外，其他 terms 的⽂档总数（总数-返回的总数）&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;13-数据建模&#34;&gt;13. 数据建模
&lt;/h1&gt;&lt;p&gt;==问题: 什么是子字段==&lt;/p&gt;
&lt;h2 id=&#34;1-字段&#34;&gt;1. 字段
&lt;/h2&gt;&lt;p&gt;字段建模过程&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;字段类型&lt;/li&gt;
&lt;li&gt;是否要搜索及分词&lt;/li&gt;
&lt;li&gt;是否需要聚合排序&lt;/li&gt;
&lt;li&gt;是否需要额外的存储&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Text 和keyword 如何选择&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/images/image-20221014113224618.png&#34;
	width=&#34;716&#34;
	height=&#34;338&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20221014113224618&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;211&#34;
		data-flex-basis=&#34;508px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;结构数据&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/images/image-20221014113346380.png&#34;
	width=&#34;621&#34;
	height=&#34;275&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20221014113346380&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;225&#34;
		data-flex-basis=&#34;541px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;==对字段的index 设置为false , 则该字段不可被搜索了, 但是还是可以进行聚合查询==&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/images/image-20221014114729839.png&#34;
	width=&#34;464&#34;
	height=&#34;346&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20221014114729839&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;134&#34;
		data-flex-basis=&#34;321px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;==关闭_source, 可以解决数据在网络中传输过大的问题==&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于需要显示的信息, 可以再查询中指定stored_fields&lt;/li&gt;
&lt;li&gt;禁止_source 后还是 可以使用hignlights API&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;2-关联数据概述&#34;&gt;2. 关联数据概述
&lt;/h2&gt;&lt;p&gt;反范式设计, 扁平数据结构&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/images/image-20221013115739991.png&#34;
	width=&#34;715&#34;
	height=&#34;366&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20221013115739991&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;195&#34;
		data-flex-basis=&#34;468px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;==Elasticsearch 处理关联关系的方法==&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/images/image-20221013115818379.png&#34;
	width=&#34;628&#34;
	height=&#34;246&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20221013115818379&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;255&#34;
		data-flex-basis=&#34;612px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;当存储的数据是对象的时候, 使用bool + must搜索可能会搜索到不需要的结果&lt;/p&gt;
&lt;p&gt;● 存储时，内部对象的边界并没有考虑在内，JSON 格式被处理成扁平式键值对的结构&lt;/p&gt;
&lt;p&gt;● 当对多个字段进⾏查询时，导致了意外的搜索结果&lt;/p&gt;
&lt;p&gt;● 可以⽤ Nested Data Type 解决这个问题&lt;/p&gt;
&lt;h2 id=&#34;3-nested-data-type&#34;&gt;3. nested data type
&lt;/h2&gt;&lt;p&gt;Nested 数据类型：允许对象数组中的对象被独⽴索引&lt;/p&gt;
&lt;p&gt;● 使⽤ nested 和 properties 关键字，将所有 actors 索引到多个分隔的⽂档&lt;/p&gt;
&lt;p&gt;● 在内部， Nested ⽂档会被保存在两个Lucene ⽂档中，在查询时做 Join 处理&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;# 创建 Nested 对象 Mapping
#PUT my_movies
{
      &amp;quot;mappings&amp;quot; : {
      &amp;quot;properties&amp;quot; : {
        &amp;quot;actors&amp;quot; : {
          &amp;quot;type&amp;quot;: &amp;quot;nested&amp;quot;,
          &amp;quot;properties&amp;quot; : {
            &amp;quot;first_name&amp;quot; : {&amp;quot;type&amp;quot; : &amp;quot;keyword&amp;quot;},
            &amp;quot;last_name&amp;quot; : {&amp;quot;type&amp;quot; : &amp;quot;keyword&amp;quot;}
          }},
        &amp;quot;title&amp;quot; : {
          &amp;quot;type&amp;quot; : &amp;quot;text&amp;quot;,
          &amp;quot;fields&amp;quot; : {&amp;quot;keyword&amp;quot;:{&amp;quot;type&amp;quot;:&amp;quot;keyword&amp;quot;,&amp;quot;ignore_above&amp;quot;:256}}
        }
      }
    }
}

# Nested 查询
#POST my_movies/_search
{
  &amp;quot;query&amp;quot;: {
    &amp;quot;bool&amp;quot;: {
      &amp;quot;must&amp;quot;: [
        {&amp;quot;match&amp;quot;: {&amp;quot;title&amp;quot;: &amp;quot;Speed&amp;quot;}},
        {
        // 需要指定关键字
          &amp;quot;nested&amp;quot;: {
            // 嵌套对象  
            &amp;quot;path&amp;quot;: &amp;quot;actors&amp;quot;,
            &amp;quot;query&amp;quot;: {
              &amp;quot;bool&amp;quot;: {
                &amp;quot;must&amp;quot;: [
                  {&amp;quot;match&amp;quot;: {
                    &amp;quot;actors.first_name&amp;quot;: &amp;quot;Keanu&amp;quot;
                  }},

                  {&amp;quot;match&amp;quot;: {
                    &amp;quot;actors.last_name&amp;quot;: &amp;quot;Hopper&amp;quot;
                  }}
                ]
              }
            }
          }
        }
      ]
    }
  }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;4-父子文档&#34;&gt;4. 父子文档
&lt;/h2&gt;&lt;p&gt;对象和nested 对象的局限性&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每次更新都需要重新索引整个对象 (根对象和嵌套对象)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ES 提供了类似关系型数据库中的Join 的实现, 使用Join 数据类型, 可以通过维护Parent / Child 的关系, 从而分离两个对象&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;父子文档是两个独立的文档&lt;/li&gt;
&lt;li&gt;更新父文档 无需重新索引子文档, 子文档不影响父文档和其他子文档&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;==Spring Data Es , Field 使用哪种类型?==&lt;/p&gt;
&lt;p&gt;==定义步骤==&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;设置索引的 Mapping&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;索引⽗⽂档&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;索引⼦⽂档&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;按需查询⽂档&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;==注意==&lt;/p&gt;
&lt;p&gt;● ⽗⽂档和⼦⽂档必须存在相同的分⽚上&lt;/p&gt;
&lt;p&gt;​	● 确保查询 join 的性能&lt;/p&gt;
&lt;p&gt;● 当指定⼦⽂档时候，必须指定它的⽗⽂档 Id&lt;/p&gt;
&lt;p&gt;​	● 使⽤ route 参数来保证，分配到相同的分⽚&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/images/image-20221013122559938.png&#34;
	width=&#34;655&#34;
	height=&#34;323&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20221013122559938&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;202&#34;
		data-flex-basis=&#34;486px&#34;
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;14-query&#34;&gt;14. query
&lt;/h1&gt;&lt;h2 id=&#34;1-query-string&#34;&gt;1. query String
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/images/image-20221013153058993.png&#34;
	width=&#34;745&#34;
	height=&#34;240&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20221013153058993&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;310&#34;
		data-flex-basis=&#34;745px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;2-simple-query-string&#34;&gt;2. simple query String
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/images/image-20221013153111400.png&#34;
	width=&#34;758&#34;
	height=&#34;289&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20221013153111400&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;262&#34;
		data-flex-basis=&#34;629px&#34;
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;15-minimum_should_match&#34;&gt;15. minimum_should_match
&lt;/h1&gt;&lt;p&gt;参考资料: &lt;a class=&#34;link&#34; href=&#34;http://events.jianshu.io/p/84789dd89dcf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://events.jianshu.io/p/84789dd89dcf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;minnum_should_match：当operator参数设置为or时，该参数用来控制匹配的分词的最少数量&lt;/p&gt;
&lt;p&gt;==bool 查询中==&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;当默认不传&lt;code&gt;minimum_should_match&lt;/code&gt;的情况下，查询分为两个情况&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当bool处在query上下文时，若must或者filter匹配了doc，那么should即使一条都不满足也可以召回doc（如图1.3.1）；&lt;/li&gt;
&lt;li&gt;当bool处于filter上下文时，或者bool处于query上下文，但没有must或者filter子句，should至少匹配一个才会召回doc（如图1.3.2）；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;参数说明&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;最低匹配的个数。也可以传入负数&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;传入的参数为百分比, 默认向下取整&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;负数表示最多不匹配的百分比50%，向下取整为&lt;strong&gt;最多不匹配的个数为1个&lt;/strong&gt;。即最少匹配个数为2个。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/images/image-20221013194229885.png&#34;
	width=&#34;363&#34;
	height=&#34;165&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20221013194229885&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;220&#34;
		data-flex-basis=&#34;528px&#34;
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;16-updatebyqueryreindex&#34;&gt;16. updateByQuery&amp;amp;reindex
&lt;/h1&gt;&lt;p&gt;⼀般在以下⼏种情况时，我们需要重建索引&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;索引的 Mappings 发⽣变更：字段类型更改，分词器及字典更新&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;索引的 Settings 发⽣变更：索引的主分⽚数发⽣改变&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;集群内，集群间需要做数据迁移&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Elasticsearch 的内置提供的 API&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Update By Query：在现有索引上重建&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在索引更新之前的数据也能被搜索到&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reindex：在其他索引上重建索引&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;创建新的正确的索引&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/images/image-20221014104113183.png&#34;
	width=&#34;272&#34;
	height=&#34;123&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20221014104113183&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;221&#34;
		data-flex-basis=&#34;530px&#34;
	
&gt;重新导入&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;reindex aip 的其他使用场景&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/images/image-20221014104259765.png&#34;
	width=&#34;372&#34;
	height=&#34;167&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20221014104259765&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;222&#34;
		data-flex-basis=&#34;534px&#34;
	
&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;如果目标索引已经存在数据的话, 需要指定额外配置, 实现对新增数据的写入&lt;/li&gt;
&lt;li&gt;支持异步的操作, wait_for_completion=false, 通过返回的taskId 查询是否完成&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;17-ingest-node-painless&#34;&gt;17. ingest node&amp;amp; painless
&lt;/h1&gt;&lt;h2 id=&#34;1-ingest-node&#34;&gt;1. ingest node
&lt;/h2&gt;&lt;p&gt;==概述==&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/images/image-20221014104814861.png&#34;
	width=&#34;739&#34;
	height=&#34;415&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20221014104814861&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;178&#34;
		data-flex-basis=&#34;427px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;可以对文档进行预处理, Es 提供了一些内置的processor, 也可以通过开发插件实现自己的processor&lt;/p&gt;
&lt;h2 id=&#34;2-painless&#34;&gt;2. painless
&lt;/h2&gt;&lt;p&gt;==简介==&lt;/p&gt;
&lt;p&gt;● Painless ⽀持所有 Java 的数据类型及 Java API ⼦集&lt;/p&gt;
&lt;p&gt;● Painless Script 具备以下特性&lt;/p&gt;
&lt;p&gt;○ ⾼性能 / 安全&lt;/p&gt;
&lt;p&gt;○ ⽀持显示类型或者动态定义类型&lt;/p&gt;
&lt;p&gt;==用途==&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;可以对⽂档字段进⾏加⼯处理&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;更新或删除字段，处理数据聚合操作&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Script Field：对返回的字段提前进⾏计算&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Function Score：对⽂档的算分进⾏处理&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在 Ingest Pipeline 中执⾏脚本&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在 Reindex API，Update By Query 时，对数据进⾏处理&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/images/image-20221014112721214.png&#34;
	width=&#34;664&#34;
	height=&#34;335&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20221014112721214&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;198&#34;
		data-flex-basis=&#34;475px&#34;
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;18-深度分页&#34;&gt;18. 深度分页
&lt;/h1&gt;&lt;p&gt;参考资料 : &lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/Quoym4438irm4Uexb40asw&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://mp.weixin.qq.com/s/Quoym4438irm4Uexb40asw&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;1-基本分页&#34;&gt;1. 基本分页
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;from + size 分页方式是 ES 最基本的分页方式，类似于关系型数据库中的 limit 方式。from 参数表示：分页起始位置；size 参数表示：每页获取数据条数&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;GET /articles/_search
{
  &amp;quot;query&amp;quot;: {
    &amp;quot;match_all&amp;quot;: {}
  },
  &amp;quot;from&amp;quot;: 10,
  &amp;quot;size&amp;quot;: 20
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%BC%80%E5%8F%91%E5%AE%9E%E5%BD%95/images/image-20221122110628443.png&#34;
	width=&#34;992&#34;
	height=&#34;381&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20221122110628443&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;260&#34;
		data-flex-basis=&#34;624px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;11-query-阶段&#34;&gt;1.1 Query 阶段
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;第一步：Client 发送查询请求到 Server 端，Node1 接收到请求然后创建一个大小为 from + size 的优先级队列用来存放结果，此时 Node1 被称为 coordinating node（协调节点）；&lt;/li&gt;
&lt;li&gt;第二步：Node1 将请求广播到涉及的 shard 上，每个 shard 内部执行搜索请求，然后将执行结果存到==自己内部的大小同样为 from+size 的优先级队列==里；&lt;/li&gt;
&lt;li&gt;第三步：每个 shard 将暂存的自身优先级队列里的结果==返给 Node1==，Node1 拿到所有 shard 返回的结果后，对==结果进行一次合并，产生一个全局的优先级队列==，存在 Node1 的优先级队列中。（如上图中，Node1 会拿到 (from + size) * 6 条数据，==这些数据只包含 doc 的唯一标识_id 和用于排序的_score==，然后 Node1 会对这些数据合并排序，选择前 from + size 条数据存到优先级队列）；&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;12-fetch-阶段&#34;&gt;1.2 Fetch 阶段
&lt;/h3&gt;&lt;h2 id=&#34;方案&#34;&gt;方案
&lt;/h2&gt;&lt;h4 id=&#34;1-使用-search_after&#34;&gt;1. &lt;strong&gt;使用 &lt;code&gt;search_after&lt;/code&gt;&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;适用场景&lt;/strong&gt;：需要严格的分页访问，且结果顺序固定（例如基于时间或 ID）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;原理&lt;/strong&gt;：利用上一页的最后一条记录的 &lt;code&gt;sort&lt;/code&gt; 值作为下一页查询的起点。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;实现步骤&lt;/strong&gt;：
&lt;ol&gt;
&lt;li&gt;在查询中设置 &lt;code&gt;sort&lt;/code&gt; 字段（如时间戳或唯一 ID）。&lt;/li&gt;
&lt;li&gt;获取第一页数据时，同时记录最后一条记录的 &lt;code&gt;sort&lt;/code&gt; 值。&lt;/li&gt;
&lt;li&gt;下一次查询时，将 &lt;code&gt;search_after&lt;/code&gt; 设置为上一页的 &lt;code&gt;sort&lt;/code&gt; 值。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;示例&lt;/strong&gt;：&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;GET /index/_search
{
  &amp;quot;size&amp;quot;: 10,
  &amp;quot;sort&amp;quot;: [&amp;quot;timestamp&amp;quot;, &amp;quot;id&amp;quot;],
  &amp;quot;search_after&amp;quot;: [1668740999999, 123]
}

&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;优点&lt;/strong&gt;：性能优于 &lt;code&gt;from+size&lt;/code&gt;，内存占用小。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;缺点&lt;/strong&gt;：需要记录每次查询的 &lt;code&gt;search_after&lt;/code&gt; 值，&lt;strong&gt;不支持直接跳页&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h4 id=&#34;2-使用-scroll-api&#34;&gt;2. &lt;strong&gt;使用 &lt;code&gt;scroll&lt;/code&gt; API&lt;/strong&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;适用场景&lt;/strong&gt;：需要从大量数据中逐页读取，例如批量数据处理。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;原理&lt;/strong&gt;：&lt;code&gt;scroll&lt;/code&gt; 会保留一个快照上下文，使得查询结果在多个请求中保持一致。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;实现步骤&lt;/strong&gt;：
&lt;ol&gt;
&lt;li&gt;初始化查询，设置 &lt;code&gt;scroll&lt;/code&gt; 参数。&lt;/li&gt;
&lt;li&gt;使用返回的 &lt;code&gt;_scroll_id&lt;/code&gt; 获取后续页面。&lt;/li&gt;
&lt;li&gt;数据处理完成后，清理上下文（&lt;code&gt;clear_scroll&lt;/code&gt;）。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;示例&lt;/strong&gt;：&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;POST /index/_search?scroll=1m
{
  &amp;quot;size&amp;quot;: 100,
  &amp;quot;query&amp;quot;: {
    &amp;quot;match_all&amp;quot;: {}
  }
}

POST /_search/scroll
{
  &amp;quot;scroll&amp;quot;: &amp;quot;1m&amp;quot;,
  &amp;quot;scroll_id&amp;quot;: &amp;quot;DXF1ZXJ5QWJvdXRDOjE2OTY3MA==&amp;quot;
}

&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;优点
&lt;ul&gt;
&lt;li&gt;高效处理深度分页。&lt;/li&gt;
&lt;li&gt;保证查询结果一致性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;缺点
&lt;ul&gt;
&lt;li&gt;不适合实时数据查询。&lt;/li&gt;
&lt;li&gt;对资源（内存和磁盘）有一定占用。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;19-拼音中文搜索&#34;&gt;19. 拼音中文搜索
&lt;/h1&gt;&lt;p&gt;在Elasticsearch中实现输入拼音也能进行模糊匹配到中文的搜索结果，可以通过以下几个步骤来实现：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;安装拼音分词器&lt;/strong&gt;：使用&lt;code&gt;elasticsearch-analysis-pinyin&lt;/code&gt;插件来实现拼音搜索。这个插件可以帮助Elasticsearch支持拼音搜索功能。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;配置索引&lt;/strong&gt;：在创建索引的时候，需要配置一个自定义的分词器（analyzer），这个分词器会使用拼音分词器来处理文本。例如，可以创建一个名为&lt;code&gt;pinyin_analyzer&lt;/code&gt;的分词器，它使用&lt;code&gt;pinyin&lt;/code&gt; tokenizer来将中文字符转换成拼音。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;字段映射&lt;/strong&gt;：在字段映射中，可以为需要进行拼音搜索的字段设置两个不同的分词器，一个用于索引时使用，一个用于搜索时使用。例如，可以为字段&lt;code&gt;content&lt;/code&gt;设置&lt;code&gt;lc_index&lt;/code&gt;作为索引分词器，&lt;code&gt;lc_search&lt;/code&gt;作为搜索分词器。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;构建查询&lt;/strong&gt;：在执行搜索时，可以使用&lt;code&gt;multi_match&lt;/code&gt;查询，它允许在多个字段上进行搜索，包括原始字段和拼音字段。这样，当用户输入拼音时，Elasticsearch会同时在原始字段和拼音字段上进行搜索。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;示例配置&lt;/strong&gt;：以下是一个配置示例，其中&lt;code&gt;title&lt;/code&gt;字段既使用了正常的分词器，也使用了拼音分词器和单字分词器&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;执行搜索&lt;/strong&gt;：在执行搜索时，可以指定查询关键词在&lt;code&gt;title&lt;/code&gt;、&lt;code&gt;title.pinyin&lt;/code&gt;和&lt;code&gt;title.word&lt;/code&gt;字段上进行匹配：&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>ElasticSearch入门</title>
        <link>https://mikeLing-qx.github.io/p/elasticsearch%E5%85%A5%E9%97%A8/</link>
        <pubDate>Fri, 03 Jan 2025 14:17:25 +0800</pubDate>
        
        <guid>https://mikeLing-qx.github.io/p/elasticsearch%E5%85%A5%E9%97%A8/</guid>
        <description>&lt;h1 id=&#34;1-es入门&#34;&gt;1. ES入门
&lt;/h1&gt;&lt;h2 id=&#34;11-简介&#34;&gt;1.1 简介
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;ElasticSearch，简称为es， es是一个开源的高扩展的分布式全文检索引擎，它可以近乎实时的存储、检索数据；本身扩展性很好，可以扩展到上百台服务器，处理&lt;strong&gt;PB级别&lt;/strong&gt;的数据。es也使用Java开发并使用Lucene作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的RESTful API来隐藏Lucene的复杂性，从而让全文搜索变得简单。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;==中文API:== &lt;a class=&#34;link&#34; href=&#34;https://elasticsearchjava-api.readthedocs.io/en/latest/index.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://elasticsearchjava-api.readthedocs.io/en/latest/index.html&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;12-es重要字段与mysql的对比&#34;&gt;1.2 es重要字段与mysql的对比
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;index  库DB&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;type   表table&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;mapping 相当于数据库的表结构&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;field  相当于mysql 表的字段&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;document 行数据 row&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;121-索引-index&#34;&gt;1.2.1 索引 Index
&lt;/h3&gt;&lt;p&gt;一个索引就是一个拥有几分相似特征的文档的集合。比如说，你可以有一个客户数据的索引，另一个产品目录的索引，还有一个订单数据的索引。==一个索引由一个名字来标识（必须全部是小写字母的==），并且当我们要对对应于这个索引中的文档进行索引、搜索、更新和删除的时候，都要使用到这个名字。在一个集群中，可以定义任意多的索引。&lt;/p&gt;
&lt;h3 id=&#34;122-类型-type&#34;&gt;1.2.2 类型 Type
&lt;/h3&gt;&lt;p&gt;在一个索引中，你可以定义一种或多种类型。一个类型是你的索引的一个逻辑上的分类/分区，其语义完全由你来定。通常，会为具有一组共同字段的文档定义一个类型。比如说，我们假设你运营一个博客平台并且将你所有的数据存储到一个索引中。在这个索引中，你可以为用户数据定义一个类型，为博客数据定义另一个类型，当然，也可以为评论数据定义另一个类型。&lt;/p&gt;
&lt;h3 id=&#34;123-文档-ducument&#34;&gt;1.2.3 文档 ducument
&lt;/h3&gt;&lt;p&gt;一个文档是一个可被索引的基础信息单元。比如，你可以拥有某一个客户的文档，某一个产品的一个文档，当然，也可以拥有某个订单的一个文档。文档以JSON（Javascript Object Notation）格式来表示，而JSON是一个到处存在的互联网数据交互格式。&lt;/p&gt;
&lt;p&gt;在一个index/type里面，你可以存储任意多的文档。注意，尽管一个文档，物理上存在于一个索引之中，==文档必须被索引/赋予一个索引的type==。&lt;/p&gt;
&lt;h3 id=&#34;124-字段-field&#34;&gt;1.2.4 字段 field
&lt;/h3&gt;&lt;p&gt;相当于是数据表的字段，对文档数据根据不同属性进行的分类标识的&lt;/p&gt;
&lt;h3 id=&#34;125-映射-mapping&#34;&gt;1.2.5 映射 mapping
&lt;/h3&gt;&lt;p&gt;mapping是&lt;strong&gt;处理数据的方式和规则方面做一些限制，如某个字段的数据类型、默认值、分词器、是否被索引等等&lt;/strong&gt;，这些都是映射里面可以设置的，其它就是处理es里面数据的一些使用规则设置也叫做映射，按着最优规则处理数据对性能提高很大，因此才需要建立映射，并且需要思考如何建立映射才能对性能更好。&lt;/p&gt;
&lt;p&gt;mapping是类似于&lt;strong&gt;数据库中的表结构定义&lt;/strong&gt;，主要作用如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;定义index下的字段名&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;定义字段类型，比如数值型、浮点型、布尔型等&lt;/li&gt;
&lt;li&gt;定义倒排索引相关的设置，比如是否索引、记录position等&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;126-cluster--node&#34;&gt;1.2.6 cluster &amp;amp; node
&lt;/h3&gt;&lt;p&gt;一个节点可以通过配置集群名称的方式来加入一个指定的集群; 默认elasticsearch&lt;/p&gt;
&lt;h3 id=&#34;126-分片和副本-shard--replicas&#34;&gt;1.2.6 分片和副本 shard &amp;amp; replicas
&lt;/h3&gt;&lt;p&gt;分片:&lt;/p&gt;
&lt;p&gt;Elasticsearch提供了将索引划分成多份的能力，这些份就叫做分片。当你==创建一个索引==的时候，你可以指定你想要的分片的数量。每个分片本身也是一个功能完善并且独立的“索引”，这个“索引”可以被放置到集群中的任何节点上。分片很重要，主要有两方面的原因： 1）允许你水平分割/扩展你的内容容量。 2）允许你在分片（潜在地，位于多个节点上）之上进行分布式的、并行的操作，进而提高性能/吞吐量。&lt;/p&gt;
&lt;p&gt;Elasticsearch允许你创建分片的一份或多份拷贝，这些拷贝叫做复制分片，或者直接叫复制。&lt;/p&gt;
&lt;p&gt;在分片/节点失败的情况下，提供了高可用性 ; 复制分片从不与原/主要（original/primary）分片置于同一节点上，==搜索可以在所有的复制上并行运行==。总之，==每个索引可以被分成多个分片==。一个索引也可以被复制0次（意思是没有复制）或多次。==一旦复制了，每个索引就有了主分片==（作为复制源的原来的分片）和==复制分片==（主分片的拷贝）之别。==分片和复制的数量可以在索引创建的时候指定==。在索引创建之后，你可以在任何时候动态地改变复制的数量，但是你事后==不能改变分片的数量==。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E5%85%A5%E9%97%A8/images/1563531703254.png&#34;
	width=&#34;812&#34;
	height=&#34;454&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1563531703254&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;178&#34;
		data-flex-basis=&#34;429px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;13-倒排索引&#34;&gt;1.3 倒排索引
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;例如我们使用新华字典查询汉字，新华字典有==&lt;strong&gt;偏旁部首的目录（索引）&lt;/strong&gt;==，我们查字首先查这个目录，找到这个目录中对应的偏旁部首，就可以通过这个目录中的偏旁部首找到这个==&lt;strong&gt;字所在的位置（文档）&lt;/strong&gt;==&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;倒排索引：通过索引找到该数据所在的文档。&lt;strong&gt;【快】&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;原理:&lt;/p&gt;
&lt;p&gt;将数据==加入==到索引库（你可以理解成另外一个数据库）时，会先提取数据中的词汇（==分词==），将==词汇加入到文档域(document)==，文档域中==记录==了==词汇==以及词汇在哪条数据记录中==出现过的数据下标==。用户在==搜索数据时==，==先将用户搜索的数据进行词汇提取==，然后把==对应词汇拿到索引域中进行匹配查找==，查找后会==找到对应的下标ID==，再根据对应==下标ID==到文档域中找==真实数据==。&lt;/p&gt;
&lt;p&gt;原始文档数据&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E5%85%A5%E9%97%A8/images/image-20210930164930185.png&#34;
	width=&#34;352&#34;
	height=&#34;260&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20210930164930185&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;135&#34;
		data-flex-basis=&#34;324px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;完整倒排索引&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;就编号8—拉斯—2—｛（3;1;&amp;lt;4&amp;gt;），（5;1;&amp;lt;4&amp;gt;）｝来说，文档频率2表示在两个文档出现。“&amp;lt;4&amp;gt;”表示单词出现的位置是文档中的第4个单词。   这个倒排索引基本上是一个完备的索引系统了，实际搜索系统的索引结构基本如此。&lt;/p&gt;
&lt;p&gt;倒排索引的结构是 ==文档编号, 出现次数, 第几个单词==&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E5%85%A5%E9%97%A8/images/image-20210930165450844.png&#34;
	width=&#34;546&#34;
	height=&#34;336&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20210930165450844&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;162&#34;
		data-flex-basis=&#34;390px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;14-es的端口&#34;&gt;1.4 es的端口
&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;有两个：
一种 是9200端口（RestClient）rest 接口，基于http协议；
另一种是用 节点的9300端口（TransportClient），基于Tcp协议,集群内部进行通信的端口；
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;15-版本变动&#34;&gt;1.5 版本变动
&lt;/h2&gt;&lt;p&gt;6.0的版本不允许一个index下面有多个type&lt;/p&gt;
&lt;p&gt;5.0的版本里面还允许&lt;/p&gt;
&lt;p&gt;mapping types这个操作在7.0里面将被删除掉&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;官方回复
Indices created in Elasticsearch 6.0.0 or later may only contain a single mapping type. Indices created in 5.x with multiple mapping types will continue to function as before in Elasticsearch 6.x. Mapping types will be completely removed in Elasticsearch 7.0.0
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;2-docker-安装-elasticsearch&#34;&gt;2. Docker 安装 elasticsearch
&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;先拉取镜像&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;docker pull elasticsearch:xxx
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;使用kibana查看es; 要把kibana和es加入同一个网络里面&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;docker network create esnet
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;安装es&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;docker run -id -p 9200:9200 -p 9300:9300 --name=es --network esnet f057ebddf832
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;出现的问题&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在es安装的时候报警告&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;IPv4 forwarding is disabled. Networking will not work.
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;在宿主机上执行echo &amp;ldquo;net.ipv4.ip_forward=1&amp;rdquo; &amp;raquo;/usr/lib/sysctl.d/00-system.conf&lt;/li&gt;
&lt;li&gt;重启network 和docker 服务:  systemctl restart network &amp;amp;&amp;amp; systemctl restart docker&lt;/li&gt;
&lt;li&gt;验证容器是否正常启动&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E5%85%A5%E9%97%A8/images/%E4%BF%AE%E6%94%B9%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE.png&#34;
	width=&#34;660&#34;
	height=&#34;306&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;修改网络配置&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;215&#34;
		data-flex-basis=&#34;517px&#34;
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;es启动之后自动关闭, docker ps 查看已启动的容器发现并没有es; 确认创建的方式是已守护式容器的方式创建的;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;查看容器的日志&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker logs -f 容器id
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E5%85%A5%E9%97%A8/images/es%E8%87%AA%E5%8A%A8%E5%85%B3%E9%97%AD%E7%9A%84%E5%8E%9F%E5%9B%A0.png&#34;
	width=&#34;842&#34;
	height=&#34;290&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;es自动关闭的原因&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;290&#34;
		data-flex-basis=&#34;696px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;可以看到是因为 max_map_count的值太小了, 需要设置到262144&lt;/p&gt;
&lt;p&gt;修改参数;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;查看max_map_count :
cat /proc/sys/vm/max_map_count
65530
 
设置max_map_count:
sysctl -w vm.max_map_count=262144
vm.max_map_count = 26214

重启容器
docker start 容器id
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;==测试使用es的http通信端口访问==&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E5%85%A5%E9%97%A8/images/%E6%88%90%E5%8A%9F%E8%AE%BF%E9%97%AE.png&#34;
	width=&#34;536&#34;
	height=&#34;464&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;成功访问&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;115&#34;
		data-flex-basis=&#34;277px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;安装chrome ==插件elasticsearch head 插件后查看es, 并创建myes索引库==&lt;/p&gt;
&lt;p&gt;#![elasticsearch Head](images\elasticsearch Head.png)&lt;/p&gt;
&lt;h1 id=&#34;3-快速安装可以直接用这个&#34;&gt;3. ==快速安装==(可以直接用这个)
&lt;/h1&gt;&lt;p&gt;安装kibana 和 es&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run -it --name=elasticsearch -d -p 9200:9200 -p 9300:9300 -p 5601:5601  f057ebddf832 (镜像id)

&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;docker run -it -d -e ELASTICSEARCH_URL=http://127.0.0.1:9200 --name kibana --network=container:elasticsearch 6f6c0975b647

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;访问&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;http://192.168.182.129:5601

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E5%85%A5%E9%97%A8/images/%E5%AE%89%E8%A3%85kibana%E6%88%90%E5%8A%9F.png&#34;
	width=&#34;1627&#34;
	height=&#34;809&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;安装kibana成功&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;201&#34;
		data-flex-basis=&#34;482px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;==kibana可以看到刚刚在eshead里面创建的索引==&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E5%85%A5%E9%97%A8/images/%E5%9C%A8eshead%E9%87%8C%E5%88%9B%E5%BB%BA%E7%9A%84index.png&#34;
	width=&#34;1222&#34;
	height=&#34;329&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;在eshead里创建的index&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;371&#34;
		data-flex-basis=&#34;891px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;安装ik分词器 (注意==必须要和es的版本一致==)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.8.9/elasticsearch-analysis-ik-6.8.9.zip

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E5%85%A5%E9%97%A8/images/%E5%AE%89%E8%A3%85ik%E5%88%86%E8%AF%8D.png&#34;
	width=&#34;1196&#34;
	height=&#34;75&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;安装ik分词&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;1594&#34;
		data-flex-basis=&#34;3827px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;这里速度太慢了; 我们直接翻墙去下然后复制到容器里面&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker cp /usr/local/elasticsearch-analysis-ik-6.8.9.zip elasticsearch:/usr/share/elasticsearch/plugins

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E5%85%A5%E9%97%A8/images/%E5%AE%89%E8%A3%85ik%E5%88%86%E8%AF%8D%E5%99%A8.png&#34;
	width=&#34;888&#34;
	height=&#34;78&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;安装ik分词器&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;1138&#34;
		data-flex-basis=&#34;2732px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;这里由于ik分词器没有进行解压; 导致 elasticsearch 容器 无法启动 ;&lt;/p&gt;
&lt;p&gt;==修改无法启动的容器中的内容==&lt;/p&gt;
&lt;p&gt;进入docker 目录&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/var/lib/docker/

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;查找与es相关的内容 移除掉这个zip包, 在windows解压后直接把文件传输到该宿主机目录下重启es即可&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;find ./ | grep elasticsearch/plugins/

&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;./overlay2/e208e75c08bda5d10b58ebd9aa5ceabe5e85b1db78a471ebf3fe468740e70d74/diff/usr/share/eh/plugins/elasticsearch-analysis-ik-6.8.9.zip&lt;/p&gt;
&lt;p&gt;进入以下目录&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd /var/lib/docker/overlay2/e208e75c08bda5d10b58ebd9aa5ceabe5e85b1db78a471ebf3fe468740e70d74/diff/usr/share/elasticsearch/plugins

&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E5%85%A5%E9%97%A8/images/%E6%9F%A5%E7%9C%8Bdocker%E7%9B%AE%E5%BD%95.png&#34;
	width=&#34;842&#34;
	height=&#34;322&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;查看docker目录&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;261&#34;
		data-flex-basis=&#34;627px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E5%85%A5%E9%97%A8/images/%E8%BF%9B%E5%85%A5%E5%AE%B9%E5%99%A8%E5%86%85%E9%83%A8.png&#34;
	width=&#34;848&#34;
	height=&#34;64&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;进入容器内部&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;1325&#34;
		data-flex-basis=&#34;3180px&#34;
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;4-ik分词器测试&#34;&gt;4. ik分词器测试
&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;智能分词器 ik_smart&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E5%85%A5%E9%97%A8/images/ik_smart%E5%88%86%E8%AF%8D%E6%B5%8B%E8%AF%95.png&#34;
	width=&#34;673&#34;
	height=&#34;843&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;ik_smart分词测试&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;79&#34;
		data-flex-basis=&#34;191px&#34;
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;最大分词 (可以看到, ==这个分词器 除了分了 &lt;code&gt;最大&lt;/code&gt; 还有 &lt;code&gt;最&lt;/code&gt;, 以及 &lt;code&gt;大&lt;/code&gt;)==&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E5%85%A5%E9%97%A8/images/ik%E6%9C%80%E5%A4%A7%E5%88%86%E8%AF%8D%E6%B5%8B%E8%AF%95.png&#34;
	width=&#34;679&#34;
	height=&#34;863&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;ik最大分词测试&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;78&#34;
		data-flex-basis=&#34;188px&#34;
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;默认分词器 ==所有的中文都是 以字符的形式进行划分的==&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E5%85%A5%E9%97%A8/images/%E9%BB%98%E8%AE%A4%E5%88%86%E8%AF%8D%E5%99%A8.png&#34;
	width=&#34;1615&#34;
	height=&#34;561&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;默认分词器&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;287&#34;
		data-flex-basis=&#34;690px&#34;
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;==注意分词会默认把英文转换成小写的==&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E5%85%A5%E9%97%A8/images/%E9%BB%98%E8%AE%A4%E4%BC%9A%E6%8A%8A%E8%8B%B1%E6%96%87%E8%BD%AC%E6%8D%A2%E6%88%90%E5%B0%8F%E5%86%99.png&#34;
	width=&#34;628&#34;
	height=&#34;870&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;默认会把英文转换成小写&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;72&#34;
		data-flex-basis=&#34;173px&#34;
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;5-kibana-使用dsl语句查询es数据&#34;&gt;5. kibana 使用dsl语句查询es数据
&lt;/h1&gt;&lt;p&gt;==只需要把语句复制进去看看效果就好了==&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E5%85%A5%E9%97%A8/images/kibana%E4%BD%BF%E7%94%A8.png&#34;
	width=&#34;1705&#34;
	height=&#34;997&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;kibana使用&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;171&#34;
		data-flex-basis=&#34;410px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;1-操作索引库-基本语句&#34;&gt;1. 操作索引库 基本语句
&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;# 查看所有索引
GET /_cat/indices?v

# 新增索引
PUT /user

# 删除索引
DELETE /user

# 查看索引所有数据
GET /user/_search

# 根据id查询
GET /user/userinfo/4

# 对搜索结果排序 (按照年龄降序)
GET /user/_search
{
  &amp;quot;query&amp;quot;:{
    &amp;quot;match_all&amp;quot;: {}
  },
  &amp;quot;sort&amp;quot;:{
    &amp;quot;age&amp;quot;:{
      &amp;quot;order&amp;quot;:&amp;quot;desc&amp;quot;
    }
  }
}

# 分页查询 from 表示从第几条数据开始查; size 每页数据量
GET /user/_search
{
  &amp;quot;query&amp;quot;:{
    &amp;quot;match_all&amp;quot;: {}
  },
  &amp;quot;sort&amp;quot;:{
    &amp;quot;age&amp;quot;:{
      &amp;quot;order&amp;quot;:&amp;quot;desc&amp;quot;
    }
  },
  &amp;quot;from&amp;quot;: 0,
  &amp;quot;size&amp;quot;: 5
}

# user索引创建映射
PUT /user/userinfo/_mapping
{
  &amp;quot;properties&amp;quot;: {
    &amp;quot;name&amp;quot;:{
      &amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;,
      &amp;quot;analyzer&amp;quot;: &amp;quot;ik_smart&amp;quot;,
      &amp;quot;search_analyzer&amp;quot;: &amp;quot;ik_smart&amp;quot;,
      &amp;quot;store&amp;quot;: false
    },
    &amp;quot;city&amp;quot;:{
      &amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;,
      &amp;quot;analyzer&amp;quot;: &amp;quot;ik_smart&amp;quot;,
      &amp;quot;search_analyzer&amp;quot;: &amp;quot;ik_smart&amp;quot;,
      &amp;quot;store&amp;quot;: false
    },
    &amp;quot;age&amp;quot;:{
      &amp;quot;type&amp;quot;: &amp;quot;long&amp;quot;,
      &amp;quot;store&amp;quot;: false
    },
    &amp;quot;description&amp;quot;:{
      &amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;,
      &amp;quot;analyzer&amp;quot;: &amp;quot;ik_smart&amp;quot;,
      &amp;quot;search_analyzer&amp;quot;: &amp;quot;ik_smart&amp;quot;,
      &amp;quot;store&amp;quot;: false
    }
  }
}

# 更新文档数据 (不保留原有数据)
PUT /user/userinfo/4
{
  &amp;quot;name&amp;quot;: &amp;quot;启祥&amp;quot;,
  &amp;quot;description&amp;quot;: &amp;quot;在广州读书,家在惠州,工作在深圳&amp;quot;
}

# 删除文档数据
DELETE /user/userinfo/2


# 新增文档数据 id=1 
PUT /user/userinfo/1
{
  &amp;quot;name&amp;quot;:&amp;quot;李四&amp;quot;,
  &amp;quot;age&amp;quot;:22,
  &amp;quot;city&amp;quot;:&amp;quot;深圳&amp;quot;,
  &amp;quot;description&amp;quot;:&amp;quot;李四来自湖北武汉！&amp;quot;
}

#新增文档数据 id=2
PUT /user/userinfo/2
{
  &amp;quot;name&amp;quot;:&amp;quot;王五&amp;quot;,
  &amp;quot;age&amp;quot;:35,
  &amp;quot;city&amp;quot;:&amp;quot;深圳&amp;quot;,
  &amp;quot;description&amp;quot;:&amp;quot;王五家住在深圳！&amp;quot;
}

#新增文档数据 id=3
PUT /user/userinfo/3
{
  &amp;quot;name&amp;quot;:&amp;quot;张三&amp;quot;,
  &amp;quot;age&amp;quot;:19,
  &amp;quot;city&amp;quot;:&amp;quot;深圳&amp;quot;,
  &amp;quot;description&amp;quot;:&amp;quot;在深圳打工，来自湖北武汉&amp;quot;
}

#新增文档数据 id=4
PUT /user/userinfo/4
{
  &amp;quot;name&amp;quot;:&amp;quot;张三丰&amp;quot;,
  &amp;quot;age&amp;quot;:66,
  &amp;quot;city&amp;quot;:&amp;quot;武汉&amp;quot;,
  &amp;quot;description&amp;quot;:&amp;quot;在武汉读书，家在武汉！&amp;quot;
}

#新增文档数据 id=5
PUT /user/userinfo/5
{
  &amp;quot;name&amp;quot;:&amp;quot;赵子龙&amp;quot;,
  &amp;quot;age&amp;quot;:77,
  &amp;quot;city&amp;quot;:&amp;quot;广州&amp;quot;,
  &amp;quot;description&amp;quot;:&amp;quot;赵子龙来自深圳宝安，但是在广州工作！&amp;quot;,
  &amp;quot;address&amp;quot;:&amp;quot;广东省茂名市&amp;quot;
}

#新增文档数据 id=6
PUT /user/userinfo/6
{
  &amp;quot;name&amp;quot;:&amp;quot;赵毅&amp;quot;,
  &amp;quot;age&amp;quot;:55,
  &amp;quot;city&amp;quot;:&amp;quot;广州&amp;quot;,
  &amp;quot;description&amp;quot;:&amp;quot;赵毅来自广州白云区，从事电子商务8年！&amp;quot;
}

#新增文档数据 id=7
PUT /user/userinfo/7
{
  &amp;quot;name&amp;quot;:&amp;quot;赵哈哈&amp;quot;,
  &amp;quot;age&amp;quot;:57,
  &amp;quot;city&amp;quot;:&amp;quot;武汉&amp;quot;,
  &amp;quot;description&amp;quot;:&amp;quot;武汉赵哈哈，在深圳打工已有半年了，月薪7500！&amp;quot;
}


&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;2-dsl查询基本语句&#34;&gt;2. DSL查询基本语句
&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;# 查询语句

# 过滤查询 term
GET _search
{
  &amp;quot;query&amp;quot;:{
    &amp;quot;term&amp;quot;:{
      &amp;quot;description&amp;quot;:&amp;quot;广州&amp;quot;
    }
  }
}

# 过滤查询 terms 可以指定多个匹配条件
GET _search
{
    &amp;quot;query&amp;quot;:{
    &amp;quot;terms&amp;quot;:{
      &amp;quot;city&amp;quot;:
        [
          &amp;quot;武汉&amp;quot;,
          &amp;quot;广州&amp;quot;
        ]
    }
  }
}

# 过滤查询 (范围过滤)
#gt表示&amp;gt; gte表示=&amp;gt;
#lt表示&amp;lt; lte表示&amp;lt;=
GET _search
{
  &amp;quot;query&amp;quot;:{
    &amp;quot;range&amp;quot;: {
      &amp;quot;age&amp;quot;: {
        &amp;quot;gte&amp;quot;: 30,
        &amp;quot;lte&amp;quot;: 57
      }
    }
  }
}


# exits 过滤查询 (可以用来查找具有某个域的数据)
GET _search
{
  &amp;quot;query&amp;quot;: {
    &amp;quot;exists&amp;quot;:{
      &amp;quot;field&amp;quot;:&amp;quot;age&amp;quot;
    }
  }
}

# bool 过滤
#must : 多个查询条件的完全匹配,相当于 and。
#must_not : 多个查询条件的相反匹配，相当于 not。
#should : 至少有一个查询条件匹配, 相当于 or。
GET _search
{
  &amp;quot;query&amp;quot;: {
    &amp;quot;bool&amp;quot;: {
      &amp;quot;must&amp;quot;: [
        {
          &amp;quot;term&amp;quot;: {
            &amp;quot;city&amp;quot;: {
              &amp;quot;value&amp;quot;: &amp;quot;深圳&amp;quot;
            }
          }
        },
        {
          &amp;quot;range&amp;quot;:{
            &amp;quot;age&amp;quot;:{
              &amp;quot;gte&amp;quot;:20,
              &amp;quot;lte&amp;quot;:30
            }
          }
        }
      ]
    }
  }
}

#字符串匹配
GET _search
{
  &amp;quot;query&amp;quot;: {
    &amp;quot;match&amp;quot;: {
      &amp;quot;description&amp;quot;: &amp;quot;惠州&amp;quot;
    }
  }
}

# 前缀匹配查询
GET _search
{
  &amp;quot;query&amp;quot;: {
    &amp;quot;prefix&amp;quot;: {
      &amp;quot;name&amp;quot;: {
        &amp;quot;value&amp;quot;: &amp;quot;赵&amp;quot;
      }
    }
  }
}

#多个域匹配搜索
GET _search
{
  &amp;quot;query&amp;quot;: {
    &amp;quot;multi_match&amp;quot;: {
      &amp;quot;query&amp;quot;: &amp;quot;深圳&amp;quot;,
      &amp;quot;fields&amp;quot;: [
        &amp;quot;city&amp;quot;,
        &amp;quot;description&amp;quot;
      ]
    }
  }
}


&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;注意
elasticsearch中本没有修改，它的修改原理是该是先删除再新增修改和新增是同一个接口，区分的依据就是id。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;3-提升查询子句-boosting-query-clause&#34;&gt;3. 提升查询子句 Boosting query clause
&lt;/h2&gt;&lt;p&gt;==bool 查询不仅能合并简单的 match, must等查询, 也能合并其他的查询, 包括其他 bool查询; &lt;strong&gt;boost 可以控制搜索权重&lt;/strong&gt;, 使得满足条件的查询 等分_score 更高, 它们的结果会出现在列表前面==&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;GET /_search
{
    &amp;quot;query&amp;quot;: {
        &amp;quot;bool&amp;quot;: {
            &amp;quot;must&amp;quot;: {
                &amp;quot;match&amp;quot;: {
                    &amp;quot;content&amp;quot;: { 
                        &amp;quot;query&amp;quot;:    &amp;quot;full text search&amp;quot;,
                        &amp;quot;operator&amp;quot;: &amp;quot;and&amp;quot;
                    }
                }
            },
            &amp;quot;should&amp;quot;: [ 
                { &amp;quot;match&amp;quot;: { &amp;quot;content&amp;quot;: &amp;quot;Elasticsearch&amp;quot; }},
                { &amp;quot;match&amp;quot;: { &amp;quot;content&amp;quot;: &amp;quot;Lucene&amp;quot;        }}
            ]
        }
    }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;指定权重&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Post /_search
{
    &amp;quot;query&amp;quot;: {
        &amp;quot;bool&amp;quot;: {
            &amp;quot;must&amp;quot;: {
                &amp;quot;match&amp;quot;: {  
                    &amp;quot;content&amp;quot;: {
                        &amp;quot;query&amp;quot;:    &amp;quot;full text search&amp;quot;,
                        &amp;quot;operator&amp;quot;: &amp;quot;and&amp;quot;
                    }
                }
            },
            &amp;quot;should&amp;quot;: [
                { &amp;quot;match&amp;quot;: {
                    &amp;quot;content&amp;quot;: {
                        &amp;quot;query&amp;quot;: &amp;quot;Elasticsearch&amp;quot;,
                        &amp;quot;boost&amp;quot;: 3 
                    }
                }},
                { &amp;quot;match&amp;quot;: {
                    &amp;quot;content&amp;quot;: {
                        &amp;quot;query&amp;quot;: &amp;quot;Lucene&amp;quot;,
                        &amp;quot;boost&amp;quot;: 2 
                    }
                }}
            ]
        }
    }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-properties&#34;&gt;boost参数被用来增加一个子句的相对权重(当boost大于1时)，或者减小相对权重(当boost介于0到1时)，但是增加或者减小不是线性的

&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;6-将数据库的数据导入到es中去&#34;&gt;6. 将数据库的数据导入到es中去
&lt;/h1&gt;&lt;p&gt;springboot整个es有四种方法，分别是TransportClient、RestClient、SpringData-Es、Elasticsearch-SQL。&lt;/p&gt;
&lt;p&gt;这里我们使用SpringData-Es;  spring-boot 版本是 2.1.17.RELEASE&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;引入依赖&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt; &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spring-boot-starter-data-elasticsearch&amp;lt;/artifactId&amp;gt;
 &amp;lt;/dependency&amp;gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;配置elasticsearch地址&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;spring:
    data:
        elasticsearch:
          cluster-name: docker-cluster
          cluster-nodes: 192.168.182.129:9300

&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;创建存入elasticsearch的 pojo类 (这里选择商标分类 trademarkclass)&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;加上了Document 注解之后, 默认情况下这个实体类中的所有属性都会被建立索引, 并且分词&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Document(indexName = &amp;quot;ipr_trademarkclass&amp;quot;, type = &amp;quot;mybunnygirl&amp;quot;) 
// 这里相当于配置的是库名,表名
public class TrademarkClassInfo {
    
    @Id
    private Integer id;

    private String ordinal;
    // 设置类型, 以及使用ik_smart分词器进行分词; 不设置则使用默认的
    @Field(type = FieldType.Text, analyzer = &amp;quot;ik_smart&amp;quot;) 
    private String name;
    @Field(type = FieldType.Text, analyzer = &amp;quot;ik_smart&amp;quot;)
    private String description;

    private Integer status;

    private String remark;

    // 这里使用localdatetime的 话 查数据的时候会有反序列化异常;使用Date 类型去替代
    private LocalDateTime created;   

    private LocalDateTime modified;
}

&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;,可以使用 elasticsearch的通用mapper操作es&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;@Repository
public interface TrademarkInfoMapper extends ElasticsearchRepository&amp;lt;TrademarkInfo, Integer&amp;gt; {
}

&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;同时需要在启动类上扫描elasticsearch的通用mapper 所在的包&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;@SpringBootApplication
@EnableElasticsearchRepositories(basePackages = &amp;quot;com.example.elasticipr.dao.esdao&amp;quot;)
@MapperScan(basePackages = &amp;quot;com.example.elasticipr.dao.sqldao&amp;quot;)
public class ElasticIprApplication {

    public static void main(String[] args) {
        SpringApplication.run(ElasticIprApplication.class, args);
    }

}

&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;
&lt;p&gt;将mysql的数据查出来后, 导入到es中&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@Service
public class ElasticsearchServiceImpl implements ElasticsearchService {

    @Autowired
    private TrademarkClassMapper trademarkClassMapper;

    @Autowired
    private TrademarkClassInfoMapper trademarkClassInfoMapper;

    @Override
    public void importTrademarkClassToEs() {
        List&amp;lt;TrademarkClass&amp;gt; trademarkClasses = trademarkClassMapper.selectAll();
        trademarkClasses.forEach(System.out::println);
        String json = JSON.toJSONString(trademarkClasses);
        List&amp;lt;TrademarkClassInfo&amp;gt; trademarkInfos = JSON.parseArray(json, TrademarkClassInfo.class);
        trademarkClassInfoMapper.saveAll(trademarkInfos);
    }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;==导入成功==&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E5%85%A5%E9%97%A8/images/%E6%8F%92%E5%85%A5%E6%95%B0%E6%8D%AE%E6%88%90%E5%8A%9F.png&#34;
	width=&#34;1487&#34;
	height=&#34;825&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;插入数据成功&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;180&#34;
		data-flex-basis=&#34;432px&#34;
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;7--用es进行查询&#34;&gt;7.  用es进行查询
&lt;/h1&gt;&lt;p&gt;==查询description字段 中带&lt;code&gt;材料&lt;/code&gt; 关键字的==&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E5%85%A5%E9%97%A8/images/%E6%9F%A5%E8%AF%A2%E6%9D%90%E6%96%99%E7%BB%93%E6%9E%9C.png&#34;
	width=&#34;1135&#34;
	height=&#34;562&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;查询材料结果&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;201&#34;
		data-flex-basis=&#34;484px&#34;
	
&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;**
     * @description: 根据关键字搜索
     * @author: Qixiang
     * @date: 2020/9/24 15:55
     * @param: searchMap
     * @return: java.util.Map
     */
    @Override
    public Map search(Map&amp;lt;String, String&amp;gt; searchMap) {
        //1.条件构建
        NativeSearchQueryBuilder builder = buildBasicQuery(searchMap);

        //2.搜索列表
        Map resultMap = searchList(builder);

        return resultMap;
    }

    /**
     * 数据搜索
     * @param builder
     * @return
     */
    private Map searchList(NativeSearchQueryBuilder builder){
        Map resultMap=new HashMap();//返回结果
        //查询解析器
        NativeSearchQuery searchQuery = builder.build();
        Page&amp;lt;TrademarkClassInfo&amp;gt; trademarkClassInfos =  esTemplate.queryForPage(searchQuery,TrademarkClassInfo.class);

        //存储对应数据
        resultMap.put(&amp;quot;rows&amp;quot;, trademarkClassInfos.getContent());
        resultMap.put(&amp;quot;totalPages&amp;quot;, trademarkClassInfos.getTotalPages());
        return resultMap;
    }

    /**
     * 构建基本查询
     * @param searchMap
     * @return
     */
    private NativeSearchQueryBuilder buildBasicQuery(Map&amp;lt;String,String&amp;gt; searchMap) {
        // 查询构建器
        NativeSearchQueryBuilder nativeSearchQueryBuilder = new NativeSearchQueryBuilder();
        if(searchMap!=null){
            //1.关键字查询
            if(!StringUtils.isEmpty(searchMap.get(&amp;quot;keyword&amp;quot;))){
                nativeSearchQueryBuilder.withQuery(QueryBuilders.matchQuery(&amp;quot;description&amp;quot;,searchMap.get(&amp;quot;keyword&amp;quot;)));
            }
        }
        return nativeSearchQueryBuilder;
    }

&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;8-打印es查询执行的sql&#34;&gt;8. 打印ES查询执行的sql
&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;NativeSearchQuery searchQuery = nativeSearchQueryBuilder.build();
LOGGER.info(&amp;quot;DSL-filter:{}&amp;quot;, searchQuery.getFilter().toString());
LOGGER.info(&amp;quot;DSL-query:{}&amp;quot;, searchQuery.getQuery().toString());


&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;9-spring-data-elastisearch-api-解析&#34;&gt;9. Spring Data ElastiSearch Api 解析
&lt;/h1&gt;&lt;h2 id=&#34;1-elasticsearchrepository&#34;&gt;1. ElasticsearchRepository
&lt;/h2&gt;&lt;p&gt;里面有几个特殊的search方法, 完成特殊查询通常需要的是的 QueryBuilder和 SearchQuery 两个参数&lt;/p&gt;
&lt;p&gt;关系图&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E5%85%A5%E9%97%A8/images/image-20210929161639503.png&#34;
	width=&#34;552&#34;
	height=&#34;405&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20210929161639503&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;136&#34;
		data-flex-basis=&#34;327px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch%E5%85%A5%E9%97%A8/images/image-20210929161918200.png&#34;
	width=&#34;589&#34;
	height=&#34;265&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20210929161918200&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;222&#34;
		data-flex-basis=&#34;533px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;实际使用中, ==主要任务就是要构建NativeSearchQuery== 来完成复杂的查询&lt;/p&gt;
&lt;p&gt;一般情况下使用Builder; 通过&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;NativeSearchQueryBuilder builder = new NativeSearchQueryBuilder();

builder.withQuery().withFilter().withSort().withHighlightFields().build();

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;QueryBuilder 主要用来构建查询条件, 过滤条件; SortBuilder 主要是构建排序&lt;/p&gt;
&lt;h2 id=&#34;2-elasticsearchtemplate&#34;&gt;2. ElasticSearchTemplate
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;更多是对ESRepository的补充，里面提供了一些更底层的方法&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;ES提供了批量插入数据的功能——bulk。 可以迅速插入百万级的数据。&lt;/p&gt;
&lt;p&gt;==mapper.saveAll 就是用了 bulkindex==&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public void bulkIndex(List&amp;lt;IndexQuery&amp;gt; queries) {
        BulkRequestBuilder bulkRequest = this.client.prepareBulk();
        Iterator var3 = queries.iterator();
 
        while(var3.hasNext()) {
            IndexQuery query = (IndexQuery)var3.next();
            bulkRequest.add(this.prepareIndex(query));
        }
 
        BulkResponse bulkResponse = (BulkResponse)bulkRequest.execute().actionGet();
        if (bulkResponse.hasFailures()) {
            Map&amp;lt;String, String&amp;gt; failedDocuments = new HashMap();
            BulkItemResponse[] var5 = bulkResponse.getItems();
            int var6 = var5.length;
 
            for(int var7 = 0; var7 &amp;lt; var6; ++var7) {
                BulkItemResponse item = var5[var7];
                if (item.isFailed()) {
                    failedDocuments.put(item.getId(), item.getFailureMessage());
                }
            }
 
            throw new ElasticsearchException(&amp;quot;Bulk indexing has failures. Use ElasticsearchException.getFailedDocuments() for detailed messages [&amp;quot; + failedDocuments + &amp;quot;]&amp;quot;, failedDocuments);
        }
    }
 
    public void bulkUpdate(List&amp;lt;UpdateQuery&amp;gt; queries) {
        BulkRequestBuilder bulkRequest = this.client.prepareBulk();
        Iterator var3 = queries.iterator();
 
        while(var3.hasNext()) {
            UpdateQuery query = (UpdateQuery)var3.next();
            bulkRequest.add(this.prepareUpdate(query));
        }
 
        BulkResponse bulkResponse = (BulkResponse)bulkRequest.execute().actionGet();
        if (bulkResponse.hasFailures()) {
            Map&amp;lt;String, String&amp;gt; failedDocuments = new HashMap();
            BulkItemResponse[] var5 = bulkResponse.getItems();
            int var6 = var5.length;
 
            for(int var7 = 0; var7 &amp;lt; var6; ++var7) {
                BulkItemResponse item = var5[var7];
                if (item.isFailed()) {
                    failedDocuments.put(item.getId(), item.getFailureMessage());
                }
            }
 
            throw new ElasticsearchException(&amp;quot;Bulk indexing has failures. Use ElasticsearchException.getFailedDocuments() for detailed messages [&amp;quot; + failedDocuments + &amp;quot;]&amp;quot;, failedDocuments);
        }
    }


&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public void bulkIndex(List&amp;lt;Person&amp;gt; personList) {
        int counter = 0;
        try {
            if (!elasticsearchTemplate.indexExists(PERSON_INDEX_NAME)) {
                elasticsearchTemplate.createIndex(PERSON_INDEX_TYPE);
            }
            List&amp;lt;IndexQuery&amp;gt; queries = new ArrayList&amp;lt;&amp;gt;();
            for (Person person : personList) {
                IndexQuery indexQuery = new IndexQuery();
                indexQuery.setId(person.getId() + &amp;quot;&amp;quot;);
                indexQuery.setObject(person);
                indexQuery.setIndexName(PERSON_INDEX_NAME);
                indexQuery.setType(PERSON_INDEX_TYPE);
 
                //上面的那几步也可以使用IndexQueryBuilder来构建
                //IndexQuery index = new IndexQueryBuilder().withId(person.getId() + &amp;quot;&amp;quot;).withObject(person).build();
 
                queries.add(indexQuery);
                if (counter % 500 == 0) {
                    elasticsearchTemplate.bulkIndex(queries);
                    queries.clear();
                    System.out.println(&amp;quot;bulkIndex counter : &amp;quot; + counter);
                }
                counter++;
            }
            if (queries.size() &amp;gt; 0) {
                elasticsearchTemplate.bulkIndex(queries);
            }
            System.out.println(&amp;quot;bulkIndex completed.&amp;quot;);
        } catch (Exception e) {
            System.out.println(&amp;quot;IndexerService.bulkIndex e;&amp;quot; + e.getMessage());
            throw e;
        }
    }

&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;
&lt;li&gt;常用 Search queries.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;  QueryBuilders.matchPhraseQuery(&amp;quot;&amp;quot;, &amp;quot;&amp;quot;).slop(2);
  QueryBuilders.termQuery();  // 不进行分词的; 而term一般适用于做过滤器filter的情况，譬如我们去查询title中包含“浣溪沙”且userId=1时，那么就可以用termQuery(&amp;quot;userId&amp;quot;, 1)作为查询的filter
  QueryBuilders.rangeQuery().gte().lte();
  QueryBuilders.matchPhraseQuery().slop();
  QueryBuilders.multiMatchQuery().type(Type.PHRASE_PREFIX);  //  slop: 查询词条能够相隔多远时仍然将文档视为匹配
  // PHRASE_PREFIX ;
  // PHRASE
  // CROSS_FIELDS 希望这个词条的分词词汇是分配到不同字段中的
  // MOST_FIELDS  越多字段匹配的文档分越高
  // BEST_FIELDS  完全匹配的文档占的评分比较高

&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;1 查询上下文：查询操作不仅仅会进行查询，还会计算分值，用于确定相关度；
2 过滤器上下文：查询操作仅判断是否满足查询条件，不会计算得分，查询的结果可以被缓存。
所以，根据实际的需求是否需要获取得分，考虑性能因素，选择不同的查询子句。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;完全包含查询&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;如果不希望ES进行分词, 我们需要配置一下Operator&lt;/p&gt;
&lt;p&gt;matchQuery，multiMatchQuery，queryStringQuery等，都可以设置operator。默认为Or，设置为And后，就会把符合包含所有输入的才查出来。
如果是and的话，譬如用户输入了5个词，但包含了4个，也是显示不出来的。我们可以通过设置精度来控制&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;QueryBuilders.multiMatchQuery().type(Type.PHRASE_PREFIX).operator(Operator.AND).minimumShouldMatch(&amp;quot;75&amp;quot;);  

// minimumShouldMatch 最少匹配了多少百分比的会查询出来

&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;合并查询&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;boolQuery, 可以设置多个条件的查询方式, 它的作用是用来组合多个Query, 支持四种组合 must, mustnot filter, should&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-properties&#34;&gt;must代表返回的文档必须满足must子句的条件，会参与计算分值；
filter代表返回的文档必须满足filter子句的条件，但不会参与计算分值；
should代表返回的文档可能满足should子句的条件，也可能不满足，有多个should时满足任何一个就可以，通过minimum_should_match设置至少满足几个。
mustnot代表必须不满足子句的条件。

&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;聚合查询&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;参考资料: &lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/winterking3/article/details/83785750&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/winterking3/article/details/83785750&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&#34;10--搭建-es集群&#34;&gt;10 . 搭建 ES集群
&lt;/h1&gt;&lt;p&gt;参考 day2 拓展&lt;/p&gt;
</description>
        </item>
        <item>
        <title>ElasticSearch_DSL语句示例与练习</title>
        <link>https://mikeLing-qx.github.io/p/elasticsearch_dsl%E8%AF%AD%E5%8F%A5%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/</link>
        <pubDate>Fri, 06 May 2022 14:22:04 +0800</pubDate>
        
        <guid>https://mikeLing-qx.github.io/p/elasticsearch_dsl%E8%AF%AD%E5%8F%A5%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/</guid>
        <description>&lt;h1 id=&#34;1-基础&#34;&gt;1. 基础
&lt;/h1&gt;&lt;p&gt;Elasticsearch 的 DSL（Domain-Specific Language）是用于查询、操作和分析数据的功能强大且灵活的查询语言。它基于 JSON 格式表达，分为两种主要类型的查询：&lt;strong&gt;精确查询（Leaf Query）&lt;/strong&gt; 和 &lt;strong&gt;复合查询（Compound Query）&lt;/strong&gt;。&lt;/p&gt;
&lt;h1 id=&#34;2-用例&#34;&gt;2. 用例
&lt;/h1&gt;&lt;p&gt;文章来源: &lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/a_liuren/article/details/111938001&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/a_liuren/article/details/111938001&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;创建index, type, 并新增一个ducument 记录, 1是索引&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;POST test1/_doc/1
{
  &amp;quot;uid&amp;quot;: &amp;quot;1234&amp;quot;,
  &amp;quot;phone&amp;quot;: &amp;quot;123456&amp;quot;,
  &amp;quot;message&amp;quot;: &amp;quot;1&amp;quot;,
  &amp;quot;msgcode&amp;quot;: &amp;quot;1&amp;quot;,
  &amp;quot;sendtime&amp;quot;: &amp;quot;2019-03-14 01:14:20&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;从数据库中查询  select * from table where id =1&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;GET test1/_doc/1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;定义索引库,  mapping 指定数据结构, settings 主要的作用就是用来修改分片和副本数&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;settings&amp;quot;: {
    &amp;quot;number_of_shards&amp;quot;: 10,
    &amp;quot;number_of_replicas&amp;quot;: 1,
    &amp;quot;refresh_interval&amp;quot;: &amp;quot;1s&amp;quot;
  },
  &amp;quot;mapping&amp;quot;: {
    &amp;quot;properties&amp;quot;: {
      &amp;quot;uid&amp;quot;: {
        &amp;quot;type&amp;quot;: &amp;quot;long&amp;quot;
      },
      &amp;quot;phone&amp;quot;: {
        &amp;quot;type&amp;quot;: &amp;quot;long&amp;quot;
      },
      &amp;quot;message&amp;quot;: {
        &amp;quot;type&amp;quot;: &amp;quot;keyword&amp;quot;
      },
      &amp;quot;msgcode&amp;quot;: {
        &amp;quot;type&amp;quot;: &amp;quot;long&amp;quot;
      },
      &amp;quot;sendtime&amp;quot;: {
        &amp;quot;type&amp;quot;: &amp;quot;date&amp;quot;,
        &amp;quot;format&amp;quot;: &amp;quot;yyyy-MM-dd HH:mm:ss&amp;quot;
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;通过主键id 修改ES数据&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;POST jason/_doc/1

{&amp;quot;uid&amp;quot;:&amp;quot;175&amp;quot;,&amp;quot;phone&amp;quot;:&amp;quot;176590660&amp;quot;,&amp;quot;message&amp;quot;:&amp;quot;章美&amp;quot;,&amp;quot;msgcode&amp;quot;:&amp;quot;1&amp;quot;,&amp;quot;sendtime&amp;quot;:&amp;quot;2020-12-14 01:14:20&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;根据id 删除数据&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;delete jason/_doc/1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;删除手机号是123456的数据&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;POST test1/_doc/_delete_by_query

{
  &amp;quot;query&amp;quot;:{
    &amp;quot;term&amp;quot;:{
      &amp;quot;phone&amp;quot;: &amp;quot;123456&amp;quot;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;根据查询结果 更新&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;POST test1/_doc/_update_by_query
{
  &amp;quot;script&amp;quot;:{
    &amp;quot;lang&amp;quot;:&amp;quot;painless&amp;quot;,
    &amp;quot;inline&amp;quot;:&amp;quot;ctx._source.remove(\&amp;quot;msgcode\&amp;quot;)&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;查询索引库中的数据&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;GET _search
{
  &amp;quot;query&amp;quot;:{
    &amp;quot;match_all&amp;quot;: {}
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;查询指定index, type 中的数据&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;GET jason/_doc/_search

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;多字段匹配&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;GET jason/_doc/_search
{
  &amp;quot;query&amp;quot;:{
    &amp;quot;terms&amp;quot;:{
      &amp;quot;uid&amp;quot;:[
        176,
        12
        ]
    }
  }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;范围查询; 需要的数据类型为数值&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;GET jason/_doc/search
{
  &amp;quot;query&amp;quot;: {
    &amp;quot;range&amp;quot;:{
      &amp;quot;uid&amp;quot;: {
        &amp;quot;gte&amp;quot;: 165,
        &amp;quot;lte&amp;quot;: 177
      }
    }
  }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;exist 存在字段查询, 其实就是非null 的字段数据&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;GET jason/_doc/_search
{
  &amp;quot;query&amp;quot;:{
    &amp;quot;exists&amp;quot;:{
      &amp;quot;field&amp;quot;: &amp;quot;uid&amp;quot;
    }
  }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;==bool 可以用来合并多个过滤条件查询结果==&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;GET jason/_doc/_search
{
  &amp;quot;query&amp;quot;:{
    &amp;quot;bool&amp;quot;:{
      &amp;quot;must&amp;quot;:{
        &amp;quot;term&amp;quot;:{
          &amp;quot;phone&amp;quot;: &amp;quot;176206660&amp;quot;
        }
      },
      &amp;quot;must_not&amp;quot;:{
        &amp;quot;term&amp;quot;:{
          &amp;quot;uid&amp;quot;: &amp;quot;7890&amp;quot;
        }
      },
      &amp;quot;should&amp;quot;:[
      {
        &amp;quot;term&amp;quot;:{
          &amp;quot;uid&amp;quot;: &amp;quot;176&amp;quot;
        }
      }
      ],
      &amp;quot;adjust_pure_negative&amp;quot;: true,
      &amp;quot;boost&amp;quot;: 1
    }
  }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;模糊查询 (比较消耗性能)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;GET jason/_doc/_search
{
  &amp;quot;query&amp;quot;:{
    &amp;quot;wildcard&amp;quot;:{
      &amp;quot;message&amp;quot;: &amp;quot;ruan*&amp;quot;
    }
  }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;正则查询&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 查询出信息为ruan到0-9的数据
GET jason/_doc/_search
{
  &amp;quot;query&amp;quot;:{
    &amp;quot;regexp&amp;quot;:{
      &amp;quot;message&amp;quot;:&amp;quot;ruan[0-9]&amp;quot;
    }
  }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;匹配查询&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;新增数据
PUT /questionnaire_record/_doc/9
{
  &amp;quot;id&amp;quot;: &amp;quot;6&amp;quot;,
  &amp;quot;uid&amp;quot;:&amp;quot;12&amp;quot;,
  &amp;quot;activityNo&amp;quot;: &amp;quot;AC20122403071370181&amp;quot;,
  &amp;quot;activityCustomType&amp;quot;:1,
  &amp;quot;elapsedTime&amp;quot;:12,
  &amp;quot;winPrize&amp;quot;: true,
  &amp;quot;browerFrom&amp;quot;:&amp;quot;wap&amp;quot;
}

匹配查询
POSt /questionnaire_record/_search
{
  &amp;quot;query&amp;quot;:
  {
    &amp;quot;match&amp;quot;:
    {
      &amp;quot;activityNo&amp;quot;: &amp;quot;AC20122403071370181&amp;quot;
    }
  }
}


&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;新增数据&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;PUT /school/student/14
{
  &amp;quot;name&amp;quot;: &amp;quot;JetWu&amp;quot;,
  &amp;quot;age&amp;quot;: 22,
  &amp;quot;city&amp;quot;: &amp;quot;chengdu&amp;quot;,
  &amp;quot;interests&amp;quot;:[&amp;quot;run&amp;quot;,&amp;quot;qiicky_run&amp;quot;,&amp;quot;mountain climbing&amp;quot;],
  &amp;quot;introduction&amp;quot;: &amp;quot;i am form hengyang. i love my hometown&amp;quot;
}

PUT /school/student/8
{
  &amp;quot;name&amp;quot;: &amp;quot;jason&amp;quot;,
  &amp;quot;age&amp;quot;: 18,
  &amp;quot;city&amp;quot;: &amp;quot;hefei&amp;quot;,
  &amp;quot;interests&amp;quot;: [&amp;quot;swiming&amp;quot;,&amp;quot;sleep&amp;quot;],
  &amp;quot;introduction&amp;quot;: &amp;quot;阳光男孩&amp;quot;
}

PUT /school/student/4
{
  &amp;quot;name&amp;quot;: &amp;quot;hello&amp;quot;,
  &amp;quot;age&amp;quot;:15,
  &amp;quot;city&amp;quot;: &amp;quot;china&amp;quot;,
  &amp;quot;interests&amp;quot;:[&amp;quot;chinese&amp;quot;,&amp;quot;game&amp;quot;],
  &amp;quot;introduction&amp;quot;:&amp;quot;大家好，我是一个宅男&amp;quot;
}

&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#都是查询在age这个字段上面非空的数据，查询出age字段上非空的数据
POST /school/student/_search
{
  &amp;quot;query&amp;quot;:
  {
  	&amp;quot;exists&amp;quot;: {
  		&amp;quot;field&amp;quot;: &amp;quot;age&amp;quot;
    }
  }
}

#前缀查询，匹配具有包含带有指定前缀的术语的字段的文档
#查询出名称这个字段上为Jason的数据
POST /school/student/_search
{
  &amp;quot;query&amp;quot;:{
    &amp;quot;prefix&amp;quot;:{&amp;quot;name&amp;quot;: {&amp;quot;value&amp;quot;: &amp;quot;jason&amp;quot;}
    }
  }
}

#通配符查询,其中*代表是所有的，?代表的就是一个字符
#wildcard有点像like关键字，查询出name在jet?u的数据
POST /school/student/_search
{
  &amp;quot;query&amp;quot;:{
    &amp;quot;wildcard&amp;quot;: {
      &amp;quot;name&amp;quot;:{&amp;quot;value&amp;quot;: &amp;quot;jet?u&amp;quot;}
    }
  }
}

#模糊查询
#该fuzzy查询将生成在中指定的最大编辑距离内的匹配术语
POST /school/student/_search
{
  &amp;quot;query&amp;quot;:{
    &amp;quot;fuzzy&amp;quot;: {
      &amp;quot;name&amp;quot;:&amp;quot;jason&amp;quot;
    }
  }
}


&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        <item>
        <title>ElasticSearch_Linux单机部署</title>
        <link>https://mikeLing-qx.github.io/p/elasticsearch_linux%E5%8D%95%E6%9C%BA%E9%83%A8%E7%BD%B2/</link>
        <pubDate>Wed, 27 Apr 2022 14:27:14 +0800</pubDate>
        
        <guid>https://mikeLing-qx.github.io/p/elasticsearch_linux%E5%8D%95%E6%9C%BA%E9%83%A8%E7%BD%B2/</guid>
        <description>&lt;h1 id=&#34;1-版本&#34;&gt;1. 版本
&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;elasticSearch&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/cn/downloads/past-releases/elasticsearch-7-17-3&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.elastic.co/cn/downloads/past-releases/elasticsearch-7-17-3&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;kibana&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.elastic.co/cn/downloads/past-releases/kibana-7-17-3&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.elastic.co/cn/downloads/past-releases/kibana-7-17-3&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ik_smart&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/medcl/elasticsearch-analysis-ik/releases/tag/v7.17.3&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/medcl/elasticsearch-analysis-ik/releases/tag/v7.17.3&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&#34;2-安装步骤&#34;&gt;2. 安装步骤
&lt;/h1&gt;&lt;h2 id=&#34;1-es&#34;&gt;1. ES
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;解压&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;tar -xvf elasticsearch-7.17.3-linux-x86_64.tar.gz
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;创建es用户&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;## ElasticSearch不能以Root身份运行， 需要单独创建一个用户， 并赋予目录权限 
groupadd elsearch

useradd elsearch -g elsearch -p elasticsearch 

chown -R elsearch:elsearch /opt/elasticsearch/elasticsearch-7.10.2
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;vi config/elasticsearch.yml 修改配置文件&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;# node名称 
node.name: node-1

# 外网访问地址
network.host: 0.0.0.0
discovery.seed_hosts: [&amp;quot;node-1&amp;quot;]
cluster.initial_master_nodes: [&amp;quot;node-1&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;启动&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;## 切换用户 
su elsearch 

## 以后台常驻方式启动 
bin/elasticsearch -d

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;启动错误&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://mikeLing-qx.github.io/p/elasticsearch_linux%E5%8D%95%E6%9C%BA%E9%83%A8%E7%BD%B2/images/image-20220928103050117.png&#34;
	width=&#34;933&#34;
	height=&#34;70&#34;
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220928103050117&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;1332&#34;
		data-flex-basis=&#34;3198px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;需要配置&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;vi /etc/sysctl.conf 添加&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;pre&gt;&lt;code&gt;vm.max_map_count=655360
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;vi /etc/security/limits.conf 末尾添加&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;pre&gt;&lt;code&gt;elsearch soft nproc 125535

elsearch hard nproc 125535
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;浏览器验证&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;http://localhost:9200/_cat/health
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;ik-smart 分词器放在 elasticsearch/plugins/ik/ 目录下, 解压重启就生效&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;3-kibana&#34;&gt;3. kibana
&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;解压&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;tar -xvf kibana-7.17.3-linux-x86_64.tar.gz
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Kibana启动不能使用root用户， 使用上面创建的elsearch用户， 进行赋权：&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;chown -R elsearch:elsearch kibana-7.10.2

&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;修改配置文件&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;# 服务端口 
server.port: 5601 

# 服务地址 
server.host: &amp;quot;0.0.0.0&amp;quot; 

# elasticsearch服务地址 
elasticsearch.hosts: [&amp;quot;http://localhost0:9200&amp;quot;]

&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;启动&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;./kibana -q

或者
nohup /bin/kibana &amp;amp;

&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;访问&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;http://localhost:5601/app/home#/

&lt;/code&gt;&lt;/pre&gt;
</description>
        </item>
        
    </channel>
</rss>
